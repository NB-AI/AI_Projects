{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Baselines II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Pipeline Steps:\n",
    "\n",
    "\n",
    "|#|Step|Check|Description|\n",
    "|---|---|---|---|\n",
    "|<font color='grey'>0</font>|<font color='grey'>Customer requirements</font>|<font color='grey'>-</font>|<font color='grey'>Get an idea of what an expected solution should do</font>|\n",
    "|1|Prepare your data|✔️|<font color='grey'>Get acquainted with the data</font>|\n",
    "|2|Come up with a baseline solution|✔️|<font color='grey'>Trivial, stable, explainable solution</font>|\n",
    "|<font color='red'>**3**</font>|<font color='red'>**Evaluate your solution**</font>|❌|<font color='red'>**Train/Test/(Val) split, calculate metrics**</font>|\n",
    "|4|Come up with improvements|✔️|<font color='grey'>Re-design/improve your recommender</font>|\n",
    "|<font color='grey'>5</font>|<font color='grey'>Deploy and support</font>|<font color='grey'>-</font>|<font color='grey'>Make sure your solution works under real-world conditions</font>|\n",
    "\n",
    "We have already done quite a lot of work. We know our data (LFM 2B) and what is available to us; in Exercise 3 we came up with a simple POP baseline recommender; we know a lot of different recommendation techniques to compare against the baseline (and going to learn even more).\n",
    "\n",
    "In order to complete the picture we need to split our data and learn how to evaluate our candidate solutions. After that we'll be able to alternate between development and evaluation to produce the final solution for our recommendation problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rely on the three files below being placed next to your jupyter notebook:\n",
    "\n",
    "* 'sampled_1000_items_inter.txt' - data about user-item interactions;\n",
    "* 'sampled_1000_items_tracks.txt' - track-related information;\n",
    "* 'sampled_1000_items_demo.txt' - user-related information;\n",
    "\n",
    "## <font color='red'>TASK 1/3</font>: Data Split (4 points)\n",
    "Write a function that randomly samples a given proportion of interactions for a test set (e.g. 0.2 == 20% of ALL interactions).\n",
    "\n",
    "### (2 points):\n",
    "* It should receive a name of a file, containing interaction data in LFM2B format (as in the previous exercise) as input.\n",
    "* The function is expected to **randomly** split the records from the file, approximately in given proportion into Train and Test sets (proportion of 0.2 means that the number of Test records to the number of Train records should be 20:80).\n",
    "* The function needs to save the result into two separate files in LFM2B format, one for Test interactions, one for Train interactions.\n",
    "\n",
    "### (2 more points):\n",
    "* Make sure that every **item from the Test** set is also **present in the Train** set.\n",
    "\n",
    "Please follow the signature below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_interactions(inter_file = 'sampled_1000_items_inter.txt',\n",
    "                       proportion = 0.2,\n",
    "                       res_test_file = 'sampled_1000_items_inter_TEST.txt',\n",
    "                       res_train_file = 'sampled_1000_items_inter_TRAIN.txt'):\n",
    "    \n",
    "    '''\n",
    "    inter_file - string - path to the file with interaction data in LFM2B format;\n",
    "    proportion - float - proportion of records from inter_file to become the Test Set;\n",
    "    res_test_file - string - Test records will be saved here;\n",
    "    res_train_file - string - Train records will be saved here;\n",
    "    \n",
    "    returns - nothing, but saves the two files in LF2B format;\n",
    "    '''\n",
    "    rnd.seed() # new seed to get a new split on every call\n",
    "    interactions = pd.read_csv(inter_file, sep='\\t', header=None, names=['user','item','num_inters'])\n",
    "\n",
    "    #---------------------#\n",
    "    # code something here #\n",
    "    test = pd.DataFrame()\n",
    "    train = interactions\n",
    "    number_needed_samples = len(interactions) * proportion\n",
    "    collected_samples_so_far = len(test)\n",
    "    interactions_it = set(list(interactions['item']))\n",
    "    \n",
    "    while  collected_samples_so_far < number_needed_samples:\n",
    "        \n",
    "        if len(interactions_it) == 0:\n",
    "            interactions_it = set(list(interactions['item']))\n",
    "            random_item = rnd.sample(interactions_it, 1) # choose random itemID\n",
    "            interactions_it.remove(random_item[0])\n",
    "            inter2 = interactions.drop(test.index, axis=0, inplace=False)\n",
    "            max_number_random_item = len(inter2[inter2['item'] == random_item[0]])-1\n",
    "        else:\n",
    "            \n",
    "            random_item = rnd.sample(interactions_it, 1) # choose random itemID\n",
    "\n",
    "            max_number_random_item = len(interactions[interactions['item'] == random_item[0]])-1\n",
    "            \n",
    "            interactions_it.remove(random_item[0]) # potential items shrinked \n",
    "        \n",
    "        \n",
    "        remaining_free_space = number_needed_samples - collected_samples_so_far\n",
    "\n",
    "        number_samples_for_testset = rnd.randint(0, min(max_number_random_item, int(remaining_free_space)+1) )\n",
    "        \n",
    "        collected_samples_so_far += number_samples_for_testset\n",
    "        \n",
    "        df_a = interactions[interactions['item']==random_item[0]]\n",
    "        random_df = df_a.sample(number_samples_for_testset,random_state=rnd.seed())\n",
    "        \n",
    "        test = pd.concat([test, random_df])\n",
    "        \n",
    "    train = train.drop(test.index, axis=0, inplace=False) # remove the testset samples from training set\n",
    "    \n",
    " \n",
    "    #---------------------#\n",
    "    \n",
    "    # saving the res files\n",
    "    # train and test - pd.DataFrames\n",
    "    train.to_csv(res_train_file, index=False, header=False, sep='\\t') \n",
    "    test.to_csv(res_test_file, index=False, header=False, sep='\\t')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/3</font>: Evaluation function (4 points)\n",
    "### (2 points): Method\n",
    "Write an evaluation function which receives the recomender to be evaluated, \"train\" and \"test\" matrices and calculates MRR (Mean Reciprocal Rank) over the users from the test set:\n",
    "\n",
    "$MRR = \\frac{1}{|T_{users}|}\\sum \\limits_{i=1}^{|T_{users}|}\\frac{1}{rank_i}$\n",
    "\n",
    "$T_{users}$ - set of users ended up in the Test Set\n",
    "\n",
    "$rank_i$ - rank of the **first relevant** track shown to the user (position of our best guess) for $i$-th user\n",
    "\n",
    "###### Example:\n",
    "Imagine that the table below is a recommendation list for user $i$, sorted in the order of descending recommendation score (the system assumes that the tracks on the top are more likely to interest the user). In the last column we have ground truth information that allows us to evaluate the system's recommendation.\n",
    "\n",
    "In this case $rank_i = 2$, as the highest on the list item, user actually interacted with, is on the second position.<br>\n",
    "This way $RR$ for user $i$ is equal to $\\frac{1}{2}$. <br>\n",
    "$MRR$ would be mean of $RR$ over all users we know ground truth about.\n",
    "\n",
    "\n",
    "| Rank | Track Name | Track ID | Interacted with in<br>the test set? |\n",
    "| ---    |   ---  |   ---  |   ---  |\n",
    "| 1 | Dido - Thank You | 432  | False |\n",
    "| 2 | U2 - Vertigo | 12  | **True** |\n",
    "| 3 | Botch - Lobster Song | 57 | False |\n",
    "| 4 | U2 - Walk On | 311 | **True** |\n",
    "\n",
    "* What should $RR$ be equal to if the system didn't guess any of the tracks the user interacted with? Why?\n",
    "* What other metric could we use to take into account hits beyond the first one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What should $RR$ be equal to if the system didn't guess any of the tracks the user interacted with? Why?<br>\n",
    "RR should be 0 because the lower the rank the closer $RR=\\frac{1}{rank_i}$ comes to 0. <br><br>\n",
    "* What other metric could we use to take into account hits beyond the first one?<br>\n",
    "Rank Correlation:\n",
    "Kendall's Tau $\\tau$ is not only considering the correctly ranked item pairs but also the incorrectly ones. Compare the interacted items of a user marked as high rank with the recommended items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_MRR(rec_func, train, test, topK = 10):\n",
    "    '''\n",
    "    rec_func - recommendation function, allowing for call: rec_func(train, user_id, topK)\n",
    "    train - 2D np.array - Train interaction matrix, as produced by inter_matr_binary from Ex3\n",
    "    test - 2D np.array - Test interaction matrix, as produced by inter_matr_binary from Ex3\n",
    "    topK - int - length of the recommended list rec_func should provide\n",
    "    \n",
    "    returns - float - MRR score\n",
    "    '''\n",
    "    MRR = 0\n",
    "\n",
    "    #---------------------#\n",
    "    # code something here # \n",
    "   \n",
    "    \n",
    "    number_users_testset = test.shape[0]\n",
    "    for user_id in range(number_users_testset):\n",
    "        \n",
    "        list_rec = list(rec_func(train,user_id,topK))\n",
    "\n",
    "        user_row = test[user_id]\n",
    "        interaction_items = np.where(user_row==1) # get indices of items interested in. These indices are\n",
    "        # also the item IDs!\n",
    "\n",
    "        interacted = list(interaction_items[0])\n",
    "        long_list = list_rec\n",
    "        long_list.extend(interacted)\n",
    "      \n",
    "\n",
    "        if len(long_list) != len(set(long_list)) and len(interacted)>0: # there are duplicates\n",
    "    \n",
    "            for inter_item in interacted:\n",
    "                if inter_item in list_rec:\n",
    "                    \n",
    "                    \n",
    "                    rank_index = list_rec.index(inter_item)\n",
    "                    break\n",
    "            MRR += float(1/(int(rank_index)+1))  \n",
    "\n",
    "    MRR = float(MRR/number_users_testset)\n",
    "    #---------------------#\n",
    "    \n",
    "    return MRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point): Evaluate your TopKPOP\n",
    "Use the evaluation function you have written to evaluate **recTopKPop** - your own baseline recommender from Exercise 3 (Task 4).\n",
    "Use your function **inter_matr_binary** from Exercise 3 (Task 1) to convert the Train and Test files into numpy arrays.\n",
    "\n",
    "Copy needed code from Exercise 3 into function-dummies below. Run the cell and allow the result to remain in the **\\_eval_res_0** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 2 evaluation result:  0.010046444342926755\n"
     ]
    }
   ],
   "source": [
    "def inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter.txt'):\n",
    "    '''\n",
    "    usr_path - string path to the file with users data;\n",
    "    itm_path - string path to the file with item data;\n",
    "    inter_path - string path to the file with interaction data;\n",
    "    \n",
    "    returns - 2D np.array, rows - users, columns - items;\n",
    "    '''\n",
    "    \n",
    "    res = None\n",
    "    \n",
    "    # ---------------------------------#\n",
    "    # your old converter function here #\n",
    "    tracks = pd.read_csv(itm_path, delimiter='\\t')\n",
    "    numb_col_tracks = tracks.shape[1]\n",
    "    tracks = pd.read_csv(itm_path, delimiter='\\t',names=[i for i in range(numb_col_tracks)]) \n",
    "    numb_tracks = tracks.shape[0]\n",
    "    \n",
    "    users = pd.read_csv(usr_path, delimiter='\\t')\n",
    "    numb_col_usr = users.shape[1]\n",
    "    users = pd.read_csv(usr_path, delimiter='\\t', names=[e for e in range(numb_col_usr)])\n",
    "    numb_usr = users.shape[0] # alter sol: len(users.index)\n",
    "    \n",
    "    res = np.zeros(shape=(numb_usr, numb_tracks)) # we need to fill this array with interactions\n",
    "    \n",
    "    inter = pd.read_csv(inter_path, delimiter='\\t')\n",
    "    numb_col_inter = inter.shape[1]\n",
    "    inter = pd.read_csv(inter_path, delimiter='\\t', names=[str(l) for l in range(numb_col_inter)])\n",
    "\n",
    "    \n",
    "    for usr_id in range(numb_usr):\n",
    "        small_inter = inter[inter['0']== usr_id]\n",
    "        list_track_id = small_inter['1'].tolist()\n",
    "        res[usr_id][list_track_id] = 1\n",
    "    # ---------------------------------#\n",
    "    \n",
    "    return res\n",
    "\n",
    "def recTopKPop(prepaired_data: np.array,\n",
    "               user: int,\n",
    "               top_k: int) -> np.array:\n",
    "    '''\n",
    "    prepaired_data - np.array from the Ex3 Task 1;\n",
    "    user - user_id, integer;\n",
    "    top_k - expected length of the resulting list;\n",
    "    \n",
    "    returns - list/array of top K popular items that the user has never seen\n",
    "              (sorted in the order of descending popularity);\n",
    "    '''\n",
    "    pop_res = None\n",
    "    \n",
    "    # --------------------------#\n",
    "    # your old recommender here #\n",
    "    active_usr_row = prepaired_data[user]\n",
    "    active_usr_find_0 = np.where(active_usr_row==0.0)[0].tolist() # these indices of features can be kept because\n",
    "    # user hasn't seen them so far\n",
    "    \n",
    "    filteredUsr_array = prepaired_data[:,active_usr_find_0] #get all rows of similar users\n",
    "    sum_col = np.sum(filteredUsr_array, axis=0).tolist()\n",
    "    ind_li = active_usr_find_0\n",
    "\n",
    "    rec1 = [(l,i) for l,i in zip(sum_col,ind_li)] # create list of tuples (numer_interact, ItemID)\n",
    "    tup_sort = sorted(rec1, key = lambda x: x[0], reverse=True) # sort by interaction amount\n",
    "    pop_res=[]\n",
    "\n",
    "    for i in tup_sort[:top_k]:\n",
    "        pop_res.append(i[1])\n",
    "\n",
    " \n",
    "    # --------------------------#\n",
    "    \n",
    "    return np.array(pop_res)\n",
    "\n",
    "# now running it all: #\n",
    "\n",
    "split_interactions()\n",
    "\n",
    "# after this the Test and Train files should be saved nearby:\n",
    "# 'sampled_1000_items_inter_TEST.txt' and 'sampled_1000_items_inter_TRAIN.txt' are ...\n",
    "# ... exppected to exist\n",
    "\n",
    "# creating the train matrix from the new saved file\n",
    "_train_matr_0 = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter_TRAIN.txt')\n",
    "\n",
    "# creating the test matrix from the new saved file\n",
    "_test_matr_0 = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter_TEST.txt')\n",
    "\n",
    "_eval_res_0 = eval_MRR(recTopKPop, _train_matr_0, _test_matr_0)\n",
    "print('\\nTask 2 evaluation result: ', _eval_res_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 point): Try different splits\n",
    "Compute MRR of recTopKPop on 10 different splits. Investigate the mean and standard deviation of the resulting distribution of scores (use numpy methods).\n",
    "\n",
    "put a 1D array of your results into the variable **_eval_10_res**, put the mean into **_eval_10_mean**, put the standard deviation into **_eval_10_std**;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR scores of recTopKPOP baseline recommender on 10 different splits:\n",
      " [0.00105325 0.01720396 0.01019978 0.01328993 0.01057186 0.04622792\n",
      " 0.03623293 0.03203125 0.03864011 0.03999709] \n",
      "\n",
      "Mean MRR on 10 runs:  0.02454480797445626 \n",
      "\n",
      "With standard deviation:  0.014945581767028522\n"
     ]
    }
   ],
   "source": [
    "_eval_10_res_0 = None\n",
    "_eval_10_mean_0 = None\n",
    "_eval_10_std_0 = None\n",
    "\n",
    "# ----------------------------------------#\n",
    "# compute MRR on 10 different data splits #\n",
    "MRRs = []\n",
    "for splitter in [0.1,0.2,0.3,0.4,0.45,0.5,0.6,0.7,0.8,0.9]:\n",
    "    split_interactions(proportion=splitter)\n",
    "    \n",
    "    train = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter_TRAIN.txt')\n",
    "    test = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter_TEST.txt')\n",
    "    \n",
    "    MRR_value = eval_MRR(recTopKPop,train,test)\n",
    "    MRRs.append(MRR_value)\n",
    "    \n",
    "_eval_10_res_0 = np.asarray(MRRs)\n",
    "_eval_10_mean_0 = _eval_10_res_0.mean()\n",
    "_eval_10_std_0 = _eval_10_res_0.std()\n",
    "   \n",
    "# ----------------------------------------#\n",
    "\n",
    "print('MRR scores of recTopKPOP baseline recommender on 10 different splits:\\n',\n",
    "      _eval_10_res_0,\n",
    "      '\\n\\nMean MRR on 10 runs: ', _eval_10_mean_0,\n",
    "      '\\n\\nWith standard deviation: ', _eval_10_std_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the results differ from split to split? Why is it so?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more items we have in the testset the more interactions are in this set. So we get a higher chance that one of these interactions also appear in the recommender list. That often leads to a higher MRR score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 3/3</font>: <font color='darkblue'>(BONUS) Improve your Baseline (4 points or ~30%)</font>\n",
    "<font color='darkblue'>This is a bonus task, it can grant you up to 0.3 of a full Exercise in case you didn't have max score on all of the previous exercises/test.\n",
    "\n",
    "Take your implementation of recTopKPop() as a base and write a new function recTopKPop_improved() (use the template below).\n",
    "Try to make it perform better in terms of MRR than the old baseline through pre-filtering the train matrix before calculating top K most popular items for every user.\n",
    "\n",
    "**Assumption: users with similar demographic characteristics (location, age, ...) share their interests.**\n",
    "\n",
    "The only difference between **recTopKPop_improved()** and its older version is that for a given user **U** the former calculates track popularity basing only on users who are similar to the user **U** according to some demographic parameters (e.g. user from UK will get recommended what is popular among UK users).\n",
    "\n",
    "**Come up with your own definition of demograpich similarity that gives improvement in MRR!**\n",
    "\n",
    "**Test your solution against the baseline on at least 10 different data splits! Try to achieve consistently superiour performance for recTopKPop_improved() through selecting filtering parameters.**\n",
    "\n",
    "Evaluate your new recommender and allow the result to be stored in the **\\_eval_res_1** variable (Your function needs to allow evaluation via **eval_MRR()**, **make sure that it is callable with three parameters, same as old topKPOP**). 'Default-value' or hardcode additional parameters if you need them. Define helper functions if you want, just make sure to preserve the interface of the improved function.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 3 evaluation result:  0.011659367061377119\n"
     ]
    }
   ],
   "source": [
    "def recTopKPop_improved(prepaired_data: np.array,\n",
    "               user: int,\n",
    "               top_k: int,\n",
    "               usr_path = 'sampled_1000_items_demo.txt',\n",
    "               itm_path = 'sampled_1000_items_tracks.txt') -> np.array:\n",
    "    '''\n",
    "    prepaired_data - np.array from the Ex3 Task 1;\n",
    "    user - user_id, integer;\n",
    "    top_k - expected length of the resulting list;\n",
    "    \n",
    "    usr_path, itm_path - files containing user and item related,\n",
    "                         use (some of) them for pre-filtering;\n",
    "    \n",
    "    returns - list/array of top K popular (demograpy aware) items that the user\n",
    "              has never seen (sorted in the order of descending popularity);\n",
    "    '''\n",
    "    pop_res = None\n",
    "    \n",
    "    #---------------------#\n",
    "    # code something here #\n",
    "   \n",
    "    usr_info = pd.read_csv(usr_path, delimiter='\\t')\n",
    "    numb_col_usr = usr_info.shape[1]\n",
    "    usr_info = pd.read_csv(usr_path, delimiter='\\t',names=[i for i in range(numb_col_usr)]) \n",
    "\n",
    "    col_names = usr_info.columns\n",
    "    \n",
    "    #we delete all columns where it has value 1:\n",
    "    active_usr_row = prepaired_data[user]\n",
    "\n",
    "    active_usr_find_0 = np.where(active_usr_row==0.0)[0].tolist() # these indices of features can be kept because\n",
    "    # werent seen by active user\n",
    "            \n",
    "\n",
    "    check_type_list = list(usr_info.loc[user])\n",
    "\n",
    "    if not pd.isna(check_type_list[0]): # then we can improve recommender\n",
    "        similar_usr_df = usr_info[usr_info[col_names[0]]==check_type_list[0]] # df with users from same country\n",
    "        \n",
    "        if len(similar_usr_df) <= 1: # there are no similar users to active user: recommend most popular items\n",
    "\n",
    "            # regular recommender:\n",
    "            \n",
    "            filteredUsr_array = prepaired_data[:,active_usr_find_0] #get all rows of similar users\n",
    "            \n",
    "            sum_col = np.sum(filteredUsr_array, axis=0).tolist()\n",
    "            ind_li = active_usr_find_0\n",
    "            rec1 = [(l,i) for l,i in zip(sum_col,ind_li)]\n",
    "            tup_sort = sorted(rec1, key = lambda x: x[0], reverse=True) # sort by interaction amount\n",
    "            pop_res=[]\n",
    "            for i in tup_sort[:top_k]:\n",
    "                pop_res.append(i[1])\n",
    "            \n",
    "        \n",
    "        else: # there exist similar users to active user\n",
    "            \n",
    "            similarUsrID = similar_usr_df.index.tolist() # which users are similar\n",
    "            \n",
    "            similarUsr_array = prepaired_data[similarUsrID][:,active_usr_find_0] #get all rows of similar users\n",
    "            \n",
    "            sum_col = np.sum(similarUsr_array, axis=0).tolist()\n",
    "            \n",
    "           \n",
    "            number_interact = len(np.where(np.array(sum_col) > 0)[0])\n",
    "            ind_li = active_usr_find_0 # get itemIDs which are relevant for top_k\n",
    "\n",
    "            rec1 = [(l,i) for l,i in zip(sum_col,ind_li)] # create list of tuples (numer_interact, ItemID)\n",
    "            tup_sort = sorted(rec1, key = lambda x: x[0], reverse=True) # sort by interaction amount\n",
    "            pop_res=[]\n",
    "\n",
    "            if number_interact < top_k: # PROBLEM\n",
    "                missing_k = top_k - number_interact\n",
    "\n",
    "                # top itemIDs of similar users\n",
    "                for i in tup_sort[:number_interact]:\n",
    "                       pop_res.append(i[1])\n",
    "\n",
    "                # top itemIDs in general (most popular):  \n",
    "                # regular recommender:\n",
    "                active_usr_row = prepaired_data[user]\n",
    "                active_usr_find_0 = np.where(active_usr_row==0.0)[0].tolist() # these indices of features can be kept because\n",
    "\n",
    "                filteredUsr_array = prepaired_data[:,active_usr_find_0] #get all rows of similar users\n",
    "\n",
    "                sum_col = np.sum(filteredUsr_array, axis=0).tolist()\n",
    "                ind_li = active_usr_find_0\n",
    "\n",
    "                rec1 = [(l,i) for l,i in zip(sum_col,ind_li)] # create list of tuples (numer_interact, ItemID)\n",
    "                tup_sort = sorted(rec1, key = lambda x: x[0], reverse=True) # sort by interaction amount\n",
    "                pop_res2=[]\n",
    "\n",
    "                for i in tup_sort[:missing_k]:\n",
    "                    pop_res2.append(i[1])\n",
    "\n",
    "              \n",
    "                # Get a final list with at first items of similar users and then items which are more general:\n",
    "                pop_res.extend(pop_res2)\n",
    "\n",
    "\n",
    "            else: # we have enough interactions to create top_k recommender list\n",
    "                rec1 = [(l,i) for l,i in zip(sum_col,ind_li)]\n",
    "                tup_sort = sorted(rec1, key = lambda x: x[0], reverse=True) # sort by interaction amount\n",
    "                pop_res=[]\n",
    "                for i in tup_sort[:top_k]:\n",
    "                    pop_res.append(i[1])\n",
    "\n",
    "            \n",
    "       \n",
    "    else: # of current user no country is given, therefore use top popular items in general\n",
    "        # regular recommender:\n",
    "        filteredUsr_array = prepaired_data[:,active_usr_find_0] #get all rows of similar users\n",
    "\n",
    "        sum_col = np.sum(filteredUsr_array, axis=0).tolist()\n",
    "        ind_li = active_usr_find_0\n",
    "        \n",
    "        rec1 = [(l,i) for l,i in zip(sum_col,ind_li)] # create list of tuples (numer_interact, ItemID)\n",
    "        tup_sort = sorted(rec1, key = lambda x: x[0], reverse=True) # sort by interaction amount\n",
    "        pop_res=[]\n",
    "\n",
    "        for i in tup_sort[:top_k]:\n",
    "            pop_res.append(i[1])\n",
    "\n",
    "    \n",
    "    #---------------------#    \n",
    "    \n",
    "    return np.array(pop_res)\n",
    "\n",
    "_eval_res_1 = eval_MRR(recTopKPop_improved, _train_matr_0, _test_matr_0)\n",
    "print('\\nTask 3 evaluation result: ', _eval_res_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='darkblue'> Demonstrate your solution in action</font>\n",
    "<font color='darkblue'>Similar to Task 2, test **both** recTopKPOP_improved and recTopKPOP on 10 different splits.\n",
    "\n",
    "Put the results as 1D arrays into **_eval_10_res_1** for the improved version and **_eval_10_res_1_old** for the old version.\n",
    "    <br>\n",
    "    \n",
    "**In each of the arrays $i$-th position should correspond to the same $i$-th split (in order to make the results comparable).**\n",
    "    <br>\n",
    "    \n",
    "Calculate and assign appropriate values for mean- and std- related variables (on these new 10 splits, for both old and new versions).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR scores of recTopKPOP_IMPROVED recommender on 10 different splits:\n",
      " [0.0036414  0.00490482 0.01527593 0.01460891 0.04036244 0.04023394\n",
      " 0.05132701 0.05066192 0.05555072 0.04393184] \n",
      "MRR of the old recTopKPOP recommender on the same 10 splits in the same order:\n",
      " [0.00167504 0.00080081 0.00707841 0.00416911 0.03056362 0.02995594\n",
      " 0.04305338 0.02837048 0.04857156 0.03274659] \n",
      "\n",
      "Mean MRR new vs old:  0.03204989292300862  vs  0.022698494275127486 \n",
      "\n",
      "Std new vs old:  0.019175537909843558  vs  0.016852958834391484\n"
     ]
    }
   ],
   "source": [
    "# results of the recTopKPOP_improved\n",
    "_eval_10_res_1 = None\n",
    "_eval_10_mean_1 = None\n",
    "_eval_10_std_1 = None\n",
    "\n",
    "# results of the old recTopKPOP\n",
    "_eval_10_res_1_old = None\n",
    "_eval_10_mean_1_old = None\n",
    "_eval_10_std_1_old = None\n",
    "\n",
    "# ----------------------------------------#\n",
    "# compute MRR on 10 different data splits #\n",
    "MRRs = []\n",
    "MRR2s = []\n",
    "for splitter in [0.1,0.2,0.3,0.4,0.45,0.5,0.6,0.7,0.8,0.9]:\n",
    "    split_interactions(proportion=splitter)\n",
    "    \n",
    "    train = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter_TRAIN.txt')\n",
    "    test = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter_TEST.txt')\n",
    "    \n",
    "    MRR_value = eval_MRR(recTopKPop,train,test)\n",
    "    MRRs.append(MRR_value)\n",
    "    \n",
    "    \n",
    "    MRR_value2 = eval_MRR(recTopKPop_improved,train,test)\n",
    "    MRR2s.append(MRR_value2)\n",
    "    \n",
    "    \n",
    "    \n",
    "_eval_10_res_1_old = np.asarray(MRRs)\n",
    "_eval_10_mean_1_old = _eval_10_res_1_old.mean()\n",
    "_eval_10_std_1_old = _eval_10_res_1_old.std()\n",
    "\n",
    "_eval_10_res_1 = np.asarray(MRR2s)\n",
    "_eval_10_mean_1 = _eval_10_res_1.mean()\n",
    "_eval_10_std_1 = _eval_10_res_1.std()\n",
    "# ----------------------------------------#\n",
    "\n",
    "print('MRR scores of recTopKPOP_IMPROVED recommender on 10 different splits:\\n',\n",
    "      _eval_10_res_1,\n",
    "      '\\nMRR of the old recTopKPOP recommender on the same 10 splits in the same order:\\n',\n",
    "      _eval_10_res_1_old,\n",
    "      '\\n\\nMean MRR new vs old: ', _eval_10_mean_1,' vs ',_eval_10_mean_1_old,\n",
    "      '\\n\\nStd new vs old: ', _eval_10_std_1,' vs ',_eval_10_std_1_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder\n",
    "* Test before you submit.\n",
    "* Cleanup the notebook after your tests, don't leave unnecessary code;\n",
    "* Restart kernel and run all cells to make sure the notebook is runnable from the beginning to the end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell the way it is, please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
