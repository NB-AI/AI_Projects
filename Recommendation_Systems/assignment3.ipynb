{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Recommendation loop, Data, Baselines\n",
    "\n",
    "## From a Customer to a Recommender System\n",
    "Below we take a look at an (overly) simplified process model of how a recommender system is (or should be) adopted.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Pipeline:\n",
    "\n",
    "**0)** Unless it is a research project, aiming to demonstrate new concepts or reach new performance heights, a **recommender system is created for a customer**. The customer sees the system as a mean to achieve some goal (e.g. earn more money).\n",
    "\n",
    "```For example an online shop wants to sell more products, attract attention to a bigger part of their product range.```\n",
    "\n",
    "```A recommender system is just one of many possible solutions.```\n",
    "\n",
    "**1)** **Data.** We start from the data, see what is available to us. At the very least we should have a log of purchases, like this:\n",
    "\n",
    "\n",
    "| Meaningless but Unique<br>Purchase Id | Products List | Quantities | Total | Date |\n",
    "| ---    |   ---  |   ---  |   ---  |   ---  |\n",
    "| 002Ax4gf... | [909] | [2]  | 26€ | 13.04.08 |\n",
    "| 9f2D4jKx... | [909, 117, 3] | [1, 1, 2]  | 102€ | 01.02.09 |\n",
    "| 3g6lP89qs.. | [3, 4] | [2, 2] | 7€ | 11.10.10 |\n",
    "| ... | ... | ... | ... | ... |\n",
    "\n",
    "A list of items should be easily accessessible as well. If we are lucky, we have some data about registered users, this can help us, for example, identify that the first two purchases were made by the same person. Demographic information, such as location and age, or user to item ratings also help a great deal.\n",
    "\n",
    "**2)** **Start simple.** As much as it is tempting to start using the data to design an effective recommendation system, we should not forget about our **customer and their interests**:\n",
    "* Customers like simple things because those are cheaper and are delivered quicker;\n",
    "* Once you design a system you need to compare it to something to confirm that it is worth spending time and money on;\n",
    "\n",
    "Therefore it is important to decide on baselines and agree on success metrics:\n",
    "* Baseline: some simple, easily explainable recommendation strategy. E.g. recommend the same set of most popular items to every user, or recommend random items to every user;\n",
    "* Success metric: discuss with your customer, what performance metric relflects their goals best? NDCG, F-1 score?\n",
    "\n",
    "**HINT:** It can happen that a simple baseline solution is already enough.\n",
    "\n",
    "**3)** **Test.** Test the solution you have under consideration, provide intuitive explanation of what the performance metrics mean. If the performance is lacking -- it is time to revise your design. Otherwise -- well done!\n",
    "\n",
    "**4)** **(re)Design.** Time to apply everything you have learned about designing recommender systems. Define problems and look for solutions, then go back to step **(3)**.\n",
    "\n",
    "**5)** **Deployment & Maintanence.** You might be asked to take part in these after-design activities as well.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### What we know:\n",
    "* We have already taken a look at various recommendation algoriths and talked about evaluation metrics (steps **3** and **4**);\n",
    "\n",
    "* Steps **0** and **5** are out of the scope of the course. We can always assume that we are our own customer. All we need is to formulate our goals clearly;\n",
    "\n",
    "* **It is time to get a better idea about those initial stages of the project: data preparation and setting baselines...**\n",
    "\n",
    "\n",
    "# <font color='red'>TASKS</font>:\n",
    "\n",
    "In this exercise you will be required to write a couple of functions and call them to produce some results saving them in given variables. See more details in every task's description.\n",
    "\n",
    "For this exercise we'll work with a tiny sample of a yet to be released LFM2B dataset. It contains listening histories of Last-fm users.\n",
    "\n",
    "These are the files which should be placed in the same folder with your notebook (find them on moodle):\n",
    "\n",
    "* 'sampled_1000_items_inter.txt' - data about user-item interactions;\n",
    "* 'sampled_1000_items_tracks.txt' - track-related information;\n",
    "* 'sampled_1000_items_demo.txt' - user-related information;\n",
    "\n",
    "The modules already imported are enough to complete the task. You are free to import more at your own risk (works relying on modules requiring installation will be ignored).\n",
    "\n",
    "\n",
    "### Data format clarifications:\n",
    "\n",
    "    'sampled_1000_items_inter.txt'\n",
    "User-item interaction:\n",
    "    \n",
    "| User Id | Track Id | Number of Interactions | \n",
    "| ---    |   ---  |   ---  |\n",
    "| 0 | 0 | 3  |\n",
    "| 0 | 6 | 5 |\n",
    "| 2 | 17 | 8 |\n",
    "| ... | ... | ... |\n",
    "\n",
    "    'sampled_1000_items_tracks.txt'\n",
    "Track-related information (line index, starting from zero, is the **Track ID**):\n",
    "\n",
    "| Artist | Track Name |\n",
    "| ---    |   ---  |\n",
    "| Helstar | Harsh Reality |\n",
    "| Carpathian Forest | Dypfryst / Dette Er Mitt Helvete |\n",
    "| Cantique Lépreux | Tourments Des Limbes Glacials |\n",
    "| ... | ... |\n",
    "\n",
    "    'sampled_1000_items_demo.txt'\n",
    "User-related information (line index, starting from zero, is the **User ID**):\n",
    "\n",
    "| Location | Age | Gender | Reg. Date |\n",
    "|   ---  |   ---  |   ---  |   ---  |\n",
    "| RU | 25  | m | 2007-10-12 18:42:00 |\n",
    "| UK | 27 | m | 2006-11-17 16:51:56 |\n",
    "| US | 22 | m | 2010-02-02 22:30:15 |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "All files are in <font color='red'>.tsv (tab '**\\t**' separated values)</font> format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 1/4</font>: Interaction Matrix \n",
    "### Method (2 points):\n",
    "Write a function that receives three file names as input and returns a 2-dimensional numpy array with the corresponding interaction matrix, where **0** means no interaction, **1** means interaction took place (any non-zero number of times).\n",
    "\n",
    "The first dimension should correspond to users, second - to items;\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter.txt'):\n",
    "    '''\n",
    "    usr_path - string path to the file with users data;\n",
    "    itm_path - string path to the file with item data;\n",
    "    inter_path - string path to the file with interaction data;\n",
    "    \n",
    "    returns - 2D np.array, rows - users, columns - items;\n",
    "    '''\n",
    "\n",
    "    tracks = pd.read_csv(itm_path, delimiter='\\t')\n",
    "    numb_col_tracks = tracks.shape[1]\n",
    "    tracks = pd.read_csv(itm_path, delimiter='\\t',names=[i for i in range(numb_col_tracks)]) \n",
    "    numb_tracks = tracks.shape[0]\n",
    "    \n",
    "    users = pd.read_csv(usr_path, delimiter='\\t')\n",
    "    numb_col_usr = users.shape[1]\n",
    "    users = pd.read_csv(usr_path, delimiter='\\t', names=[e for e in range(numb_col_usr)])\n",
    "    numb_usr = users.shape[0]\n",
    "    \n",
    "    res = np.zeros(shape=(numb_usr, numb_tracks)) # we need to fill this array with interactions\n",
    "    \n",
    "    inter = pd.read_csv(inter_path, delimiter='\\t')\n",
    "    numb_col_inter = inter.shape[1]\n",
    "    inter = pd.read_csv('sampled_1000_items_inter.txt', delimiter='\\t', names=[str(l) for l in range(numb_col_inter)])\n",
    "\n",
    "    \n",
    "    for usr_id in range(numb_usr):\n",
    "        small_inter = inter[inter['0']== usr_id]\n",
    "        list_track_id = small_inter['1'].tolist()\n",
    "        res[usr_id][list_track_id] = 1\n",
    "            \n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application (1 point):\n",
    "Using the files we discussed above, create an interaction matrix corresponding to the requirements of the first part of the task and assign it to the variable **_interaction_matrix_test**. You can use your function to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_interaction_matrix_test = inter_matr_binary(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                      itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                      inter_path = 'sampled_1000_items_inter.txt')# Change NONE to something else #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/4</font> <font color='darkblue'>(BONUS): Interaction Matrix 2</font>\n",
    "<font color='darkblue'> This task will only grant points (1-2, or about 10% of one whole exercise) to those who didn't get full points on both Exercise 1 and the Test. It will be checked regardless though. </font>\n",
    "\n",
    "<font color='darkblue'>Write a function that receives three file names as input and returns a 2-dimensional numpy array with the corresponding interaction matrix, **based on playcounts** (number of interactions). There **0** means no interaction, value from **(0,1]** means interaction took place. **For every user the sum of the corresponding row should be equal to 1**!\n",
    "\n",
    "$u$ - User\\\n",
    "$i$ - Item\\\n",
    "$I$ - Full set of Items\\\n",
    "$res_{u,i}$ - element of the resulting interaction matrix for user $u$ and item $i$;\\\n",
    "$C_{u,i}$ - Playcount for user $u$ and item $i$\\\n",
    "<br>\n",
    "$res_{u,i} = \\frac{C_{u,i}}{\\sum \\limits _{t \\in I} C_{u,t}}$\n",
    "\n",
    "The first dimension should correspond to users, second - to items;\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not beautiful.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_prob(usr_path = 'sampled_1000_items_demo.txt',\n",
    "                    itm_path = 'sampled_1000_items_tracks.txt',\n",
    "                    inter_path = 'sampled_1000_items_inter.txt'):\n",
    "    '''\n",
    "    usr_path - string path to the file with users data;\n",
    "    itm_path - string path to the file with item data;\n",
    "    inter_path - string path to the file with interaction data;\n",
    "    \n",
    "    returns - 2D np.array, rows - users, columns - items;\n",
    "    '''\n",
    "    tracks = pd.read_csv(itm_path, delimiter='\\t')\n",
    "    numb_col_tracks = tracks.shape[1]\n",
    "    tracks = pd.read_csv(itm_path, delimiter='\\t',names=[i for i in range(numb_col_tracks)]) \n",
    "    numb_tracks = tracks.shape[0]\n",
    "    \n",
    "    users = pd.read_csv(usr_path, delimiter='\\t')\n",
    "    numb_col_usr = users.shape[1]\n",
    "    users = pd.read_csv(usr_path, delimiter='\\t', names=[e for e in range(numb_col_usr)])\n",
    "    numb_usr = users.shape[0]\n",
    "    \n",
    "    res = np.zeros(shape=(numb_usr, numb_tracks)) # we need to fill this array with interactions\n",
    "    \n",
    "    inter = pd.read_csv(inter_path, delimiter='\\t')\n",
    "    numb_col_inter = inter.shape[1]\n",
    "    inter = pd.read_csv('sampled_1000_items_inter.txt', delimiter='\\t', names=[str(l) for l in range(numb_col_inter)])\n",
    "\n",
    "    \n",
    "    for usr_id in range(numb_usr):\n",
    "        small_inter = inter[inter['0']== usr_id]\n",
    "        list_track_id = small_inter['1'].tolist()\n",
    "        \n",
    "        # Change begin\n",
    "        pd.to_numeric(small_inter['2'])\n",
    "        \n",
    "        list_inter_value = small_inter['2'].tolist()\n",
    "        \n",
    "        sum_playcount = sum(list_inter_value)\n",
    "        list_inter_value = np.divide(list_inter_value, sum_playcount)\n",
    "        \n",
    "        res[usr_id][list_track_id] = list_inter_value\n",
    "        # Change end\n",
    "        \n",
    "\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 3/4</font>: Most popular Items\n",
    "### (1 point)\n",
    "Write some code to put a list of top 10 most popular **(interacted by most different users with)** items to the variable **_top_pop_10** (sorted in the order of descending popularity).\n",
    "The variable should contain a list or a 1D numpy array of length 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inser some code here\n",
    "\n",
    "top_values = list('0'*10)\n",
    "top_values = list(map(int,top_values))\n",
    "top_it = list('0'*10)\n",
    "top_it = list(map(int,top_values))\n",
    "\n",
    "for ind in range(_interaction_matrix_test.shape[1]):\n",
    "    current_sum = sum(_interaction_matrix_test.T[ind])\n",
    "    smallest_value = min(top_values)\n",
    "    if smallest_value < current_sum:\n",
    "        smallest_ind = top_values.index(smallest_value)\n",
    "        top_values[smallest_ind] = current_sum \n",
    "        top_it[smallest_ind] = ind\n",
    "    \n",
    "co2 = [(value,int(index)) for value,index in zip(top_values,top_it)]\n",
    "\n",
    "co3 = (sorted(co2, key = lambda x: x[0]))\n",
    "co4 = np.flip(co3) # also within tuples flipping! (index,value)\n",
    "co5 = []\n",
    "for final,rest in co4:\n",
    "    co5.append(int(final))\n",
    "\n",
    "_top_pop_10 = co5 #[42, 43, 51, 96, 105, 151, 12, 104, 68, 150] # Change NONE to something else \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 4/4</font>: POP Recommender\n",
    "### (3 points)\n",
    "Write a function that recommends K most popular items to a given user, **making sure that the user hasn't seen any of the recommended items before.**\n",
    "\n",
    "The function should take three arguments: np.array from task 1 (your prepaired data), user ID (int) and K (int > 0).\n",
    "Expected return: a list or a 1D array of length K (sorted in the order of descending popularity).\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recTopKPop(prepaired_data: np.array,\n",
    "               user: int,\n",
    "               top_k: int) -> np.array:\n",
    "    '''\n",
    "    prepaired_data - np.array from the task 1;\n",
    "    user - user_id, integer;\n",
    "    top_k - expected length of the resulting list;\n",
    "    \n",
    "    returns - list/array of top K popular items that the user has never seen\n",
    "              (sorted in the order of descending popularity);\n",
    "    '''\n",
    "    \n",
    "    user_row = prepaired_data[user]\n",
    "    \n",
    "    top_values = list('0'*top_k)\n",
    "    top_values = list(map(int,top_values))\n",
    "    top_it = list('0'*top_k)\n",
    "    top_it = list(map(int,top_values))\n",
    "\n",
    "    for ind in range(prepaired_data.shape[1]):\n",
    "        current_sum = sum(prepaired_data.T[ind])\n",
    "        smallest_value = min(top_values)\n",
    "        user_column = user_row[ind]\n",
    "        if smallest_value < current_sum and user_column == 0:\n",
    "            smallest_ind = top_values.index(smallest_value)\n",
    "            top_values[smallest_ind] = current_sum \n",
    "            top_it[smallest_ind] = ind\n",
    "\n",
    "\n",
    "    co2 = [(value,int(index)) for value,index in zip(top_values,top_it)]\n",
    "\n",
    "    co3 = (sorted(co2, key = lambda x: x[0]))\n",
    "\n",
    "    co4 = np.flip(co3) # also within tuples flipping! (index,value)\n",
    "    pop_res = []\n",
    "    for final,rest in co4:\n",
    "        pop_res.append(int(final))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pop_res # [42, 43, 51, 96, 105, 151, 12, 104, 68, 150] result for final check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final check\n",
    "* Remove all the code you don't need;\n",
    "* In your notebook window, do [Kernel] -> [Restart & Run All];\n",
    "* Make sure the cell below prints sensible values;\n",
    "* Don't forget to rename the notebook before submission;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Task 1.1:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]] \n",
      " Task 1.2:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]] \n",
      " Task 2.0:  [[0.13043478 0.13043478 0.2173913  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.1        0.         ... 0.         0.         0.        ]] \n",
      " Task 3.0:  [42, 43, 51, 96, 105, 151, 12, 104, 68, 150] \n",
      " Task 4.0:  [42, 43, 51, 96, 105, 151, 12, 104, 68, 150]\n"
     ]
    }
   ],
   "source": [
    "print('\\n',\n",
    "      'Task 1.1: ',inter_matr_binary(),'\\n',\n",
    "      'Task 1.2: ',_interaction_matrix_test, '\\n',\n",
    "      'Task 2.0: ',inter_matr_prob(),'\\n',\n",
    "      'Task 3.0: ',_top_pop_10, '\\n',\n",
    "      'Task 4.0: ',recTopKPop(_interaction_matrix_test, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell the way it is, please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
