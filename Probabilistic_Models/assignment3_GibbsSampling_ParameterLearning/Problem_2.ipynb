{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37947954259d35f2fcf85ce5dea0c65",
     "grade": false,
     "grade_id": "cell-d6e49c0f3b2294e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bayesian_network import BayesNet\n",
    "from utils import sample_forward, get_default_bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f12d6681c911844a780baf4557356f3",
     "grade": false,
     "grade_id": "cell-cbf36ef06ad975a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Parameter Learning\n",
    "\n",
    "In this problem, we will assume that a fixed dependency graph structure between variables is given and learn the parameters (the complete Conditional Probability Distribution Table (CPDT)) from a set of events. Furthermore, we will use log-likelihood to find a model structure that also generalizes to future data.\n",
    "    \n",
    "## ML Estimates for Conditional Distributions\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>maximum_likelihood_estimate</i> function, which computes the Maximum Likelihood Estimate for the parameters of a discrete (conditional) probability distribution $ P(X \\mid \\mathit{pa}(X) )$, given a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`maximum_likelihood_estimate` takes  three parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `variable_id` is the column index of the variable to estimate the distribution for.\n",
    "- `parent_ids` is a tuple, containing the column indices of parent variables.\n",
    "- `alpha` is a non-negative integer, corresponding to pseudocounts in Laplace smoothing.\n",
    "\n",
    "`maximum_likelihood_estimate` must return one object:\n",
    "- A Maximum Likelihood Estimate (MLE) of the parameters in form of a `np.ndarray`. The first dimension (index `0`) of the returned array must correspond to variable `variable_id`, the remaining dimensions must be sorted according to `parent_ids`. Altogether, tuple `(variable_id, ) + parent_ids` gives the mapping of dimensions to variables.\n",
    "\n",
    "Hint:\n",
    "- Assume that all variables are boolean.\n",
    "- To count elements in a Numpy array, you simply loop over the data array.\n",
    "- The smoothing parameter `alpha` is added to the counts of each possible event represented in the CPDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e93fc8cd23615080625ca14bbff79e",
     "grade": false,
     "grade_id": "cell-436ef56fc07b775c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_estimate(data: np.ndarray, variable_id: int, parent_ids: tuple=tuple(), alpha: int=0):\n",
    "    \"\"\"\n",
    "    Estimates the conditional probability distribution of a (discrete) variable from data.\n",
    "    :param data:    data to estimate distribution from\n",
    "    :param variable_id:  column index corresponding to the variable we estimate the distribution for\n",
    "    :param parent_ids: column indices of the variables the distribution is conditioned on\n",
    "    :param alpha: smoothing parameter, pseudocounts\n",
    "    :returns: estimated conditional probability distribution table\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(variable_id) == int\n",
    "    assert type(parent_ids) == tuple\n",
    "    \n",
    "    # mapping of axis to variable_id,\n",
    "    # e.g. the variable with id variable_ids[i] is on axis i of the CPDT\n",
    "    variable_ids = (variable_id,) + parent_ids\n",
    "    \n",
    "    # create output array:\n",
    "    # in the instructions stand that we can assume all variables to be boolean:\n",
    "    shaper = tuple([2]*(1+len(parent_ids)))\n",
    "    cpdt_counter = np.zeros(shaper)\n",
    "    \n",
    "    \n",
    "    for sample in data:\n",
    "        \n",
    "        var_value_id = sample[variable_id]\n",
    "        count_mask = [var_value_id]\n",
    "        \n",
    "        for put_in_id, parent_id in enumerate(parent_ids):\n",
    "            \n",
    "            parent_value_id = sample[parent_id]\n",
    "            count_mask.append(parent_value_id)\n",
    "            \n",
    "        cpdt_counter[tuple(count_mask)] += 1 \n",
    "    \n",
    "    denominator = np.sum(cpdt_counter, axis=0, keepdims=True) # at axis=0 we have the variable of interest\n",
    "\n",
    "    cpdt = (cpdt_counter+alpha)/(denominator+alpha*2) # the 2 represents \"k\", the number of possible \n",
    "    # variable values (binary --> 2)\n",
    "\n",
    "    return cpdt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e64485165c8633ae69c633bd1e3edc8a",
     "grade": true,
     "grade_id": "cell-1c8f099373bf6fc1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "_A_, _B_, _C_, _D_, _E_ = 0, 1, 2, 3, 4\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# get exact A form bayes net\n",
    "expected = bayes_net[_A_].pdt[:,0,0,0,0]\n",
    "# estimate A from the data\n",
    "actual = maximum_likelihood_estimate(data, _A_)\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.05))\n",
    "\n",
    "# get exact B_A form bayes net\n",
    "expected = bayes_net[_B_].pdt[:,:,0,0,0].T\n",
    "# estimate B_A from data\n",
    "actual = maximum_likelihood_estimate(data, _B_, (_A_,))\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.05))\n",
    "\n",
    "# test if alpha correctly added\n",
    "expected = [0.29166667, 0.70833333]\n",
    "# estimate A from the data with alpha=10\n",
    "actual = maximum_likelihood_estimate(data, _A_, alpha=10)\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.0001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cedffdc1886efc3d1407de536e6c4db6",
     "grade": false,
     "grade_id": "cell-266284793d5b1fa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Log-Likelihood Function\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>log_likelihood</i> function, which computes the log-likelihood $\\mathcal{L}(\\mathcal{M} : \\mathcal{D})$ of a model (BayesNet) relative to a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`log_likelihood` takes two parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `bayes_net` a BayesNet object representing the model $\\mathcal{M}$ (containing already estimated CPDTs).\n",
    "\n",
    "`log_likelihood` must return one object:\n",
    "- The log-likelihood of the model given the data (i.e., a floating point number (<= 0)).\n",
    "\n",
    "Hint:\n",
    "- Recall that iterating over the variables in the BayesNet is super easy: `for variable in bayes_net: ...`.\n",
    "- The probability distribution of variable $X$ given its parents $\\mathit{pa}(X)$, $P(X \\mid \\mathit{pa}(X))$, can be obtained by passing the random event to the variable, i.e., `variable(data[i])`.\n",
    "- Use the natural logarithm for your computations, i.e. `np.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee480429f8e2cb73da6c99354ff29bc6",
     "grade": false,
     "grade_id": "cell-05bb2766b425e4ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood(data: np.ndarray, bayes_net: BayesNet):\n",
    "    \"\"\"\n",
    "    Computes the log-likelihood of a given Bayesian network relative to the data.\n",
    "    :param data: data to compute the log-likelihood relative to.\n",
    "    :param bayes_net: Bayesian network model.\n",
    "    :returns: the log-likelihood of the Bayesian network relative to the data.\n",
    "    \"\"\"    \n",
    "\n",
    "    ll = 0\n",
    "    \n",
    "    for sample_ind, sample in enumerate(data):\n",
    "        \n",
    "        for variable in bayes_net:\n",
    "            \n",
    "            P_X_paX = variable(sample)\n",
    "            \n",
    "            ll += np.log(P_X_paX[sample[variable.id]]) # only consider the event which actually happend:\n",
    "            # sample[variable.id]\n",
    "\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10cb46e7d0cb2b0175e85aeabbfefbe7",
     "grade": true,
     "grade_id": "cell-fb8f52c535549516",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# expected log-likelihood\n",
    "expected = -215.9\n",
    "# actual log-likelihood\n",
    "actual = log_likelihood(data, bayes_net)\n",
    "\n",
    "# must be close\n",
    "assert np.all(np.isclose(expected, actual, atol=0.1))\n",
    "\n",
    "\n",
    "# remove unused variables\n",
    "del data\n",
    "del bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c2d3edcff0c432d9f22755cb1881941",
     "grade": false,
     "grade_id": "cell-46024e03394db093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding a Model for Strokes   \n",
    "\n",
    "After watching hours of medical dramas on television, a medicine freshman tries to figure out the perfect prediction model for strokes. Some of her computer science colleagues told her about how Bayesian networks can be used for symptom diagnosis, so she decides to model her ideas using this technique. In order to find out the (conditional) probability distributions, she needs to find a lot of training examples.\n",
    "\n",
    "Let's assume that we magically know the true underlying Bayes model (structure and parameters) and we can generate the data for her:\n",
    "\n",
    "All variables in this example are boolean (false=0 or true=1).  \n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod2.svg\">\n",
    "\n",
    "The conditional probability tables are given as follows:\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>-</td><td>0.01</td><td>0.99</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(H | A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>$h_0$</td><td>0.9</td><td>0.8</td></tr><tr><td>$h_1$</td><td>0.1</td><td>0.2</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(S | H)</th><th>$h_0$<br></th><th>$h_1$</th></tr><tr><td>$s_0$</td><td>0.9</td><td>0.85</td></tr><tr><td>$s_1$</td><td>0.1</td><td>0.15</td></tr></table>\n",
    "\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th rowspan=\"2\">P(C | A, S)</th><th colspan=\"2\">$a_0$<br></th><th colspan=\"2\">$a_1$</th></tr><tr><td>$s_0$</td><td>$s_1$</td><td>$s_0$</td><td>$s_1$</td></tr><tr><td>$c_0$<br></td><td>0.8</td><td>0.7</td><td>0.85</td><td>0.45</td></tr><tr><td>$c_1$</td><td>0.2</td><td>0.3</td><td>0.15</td><td>0.55</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(V | S)</th><th>$s_0$</th><th>$s_1$</th></tr><tr><td>$v_0$</td><td>0.1</td><td>0.2</td></tr><tr><td>$v_1$</td><td>0.9</td><td>0.8</td></tr></table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41b23a859b8a8761fa23c6536fe7429a",
     "grade": false,
     "grade_id": "cell-2e0a9f7bef60a27e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's sample 5000 events from this network as the training data, and 5000 samples as the test data for her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5160c810b8a4993a4a948deed9fa0d2",
     "grade": false,
     "grade_id": "cell-4c0f9e2cac1e27af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "A = np.array([0.01, 0.99])\n",
    "H_A = np.array([[0.9, 0.8], [0.1, 0.2]])\n",
    "S_H = np.array([[0.9, 0.85], [0.1, 0.15]])\n",
    "C_AS = np.array([[[0.8, 0.7], [0.85, 0.45]], [[0.2, 0.3], [0.15, 0.55]]])\n",
    "V_S = np.array([[0.1, 0.2], [0.9, 0.8]])\n",
    "\n",
    "# this bayes net represents the true underlying full joint distribution in the medical world \n",
    "# of our medicine freshman\n",
    "true_bayes_net = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "np.random.seed(0)\n",
    "train = sample_forward(true_bayes_net, 5000)\n",
    "test = sample_forward(true_bayes_net, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459c15ec9089733c14868e31c0435cfe",
     "grade": false,
     "grade_id": "cell-461bf6d16acbfa3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for the true underlying network structure and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "  \n",
    "  \n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34703c76c2900f4125d1e0b31852e752",
     "grade": false,
     "grade_id": "cell-adce166a4d080cf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H_A, S_H, C_AS, V_S = None, None, None, None, None\n",
    "\n",
    "for variable in true_bayes_net:\n",
    "    \n",
    "    P_est = maximum_likelihood_estimate(data=train, variable_id=variable.id, parent_ids=tuple(variable.parents), alpha=0)\n",
    "    \n",
    "    if variable.id == 0:\n",
    "        A = P_est\n",
    "    elif variable.id == 1:\n",
    "        H_A = P_est\n",
    "    elif variable.id == 2:\n",
    "        S_H = P_est\n",
    "    elif variable.id == 3:\n",
    "        C_AS = P_est\n",
    "    elif variable.id == 4:\n",
    "        V_S = P_est\n",
    "    \n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H_A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S_H.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C_AS.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V_S.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_1 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_1 = log_likelihood(data=train, bayes_net=bayes_net_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "918dcd10a1ae90d0bc22830499e3de6e",
     "grade": true,
     "grade_id": "cell-aee49c763a9fe1a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_1 < -8500\n",
    "assert tr_log_likelihood_1 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0edf90bd99b75a1a3beb63f3e83bd03f",
     "grade": false,
     "grade_id": "cell-262f7422251f2622",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Back to our medicine freshman: Having no idea of the true underlying network structure, she decides to try out the following very simple model first:\n",
    "    \n",
    "<img style='width:100%;  max-width:400px;' src=\"img/bn_mod1.svg\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for the this model and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e419893d0128bfe05a9abe6e7415328",
     "grade": false,
     "grade_id": "cell-11b996647bc6f74c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H, S, C, V = None, None, None, None, None\n",
    "\n",
    "for variable in true_bayes_net:\n",
    "    \n",
    "    P_est = maximum_likelihood_estimate(data=train, variable_id=variable.id, parent_ids=tuple(), alpha=0)\n",
    "    \n",
    "    if variable.id == 0:\n",
    "        A = P_est\n",
    "    elif variable.id == 1:\n",
    "        H = P_est\n",
    "    elif variable.id == 2:\n",
    "        S = P_est\n",
    "    elif variable.id == 3:\n",
    "        C = P_est\n",
    "    elif variable.id == 4:\n",
    "        V = P_est\n",
    "    \n",
    "\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_2 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H, (_H_,)),\n",
    "    (S, (_S_,)),\n",
    "    (C, (_C_,)),\n",
    "    (V, (_V_,))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_2 = log_likelihood(data=train, bayes_net=bayes_net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b8bd563930aaaadc2b9083539df8a8",
     "grade": true,
     "grade_id": "cell-b30990c4827845f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_2 < -8500\n",
    "assert tr_log_likelihood_2 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d174890d6759caf74ded27dae5b2572",
     "grade": false,
     "grade_id": "cell-d0193730bdfc314d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Unhappy with the result, she decides to try out a second, more complex model:\n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod3.svg\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for the this model and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36794cfa03210bd015bb0528213caa23",
     "grade": false,
     "grade_id": "cell-385934a752ed9259",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H_A, S_AH, C_AS, V_CS = None, None, None, None, None\n",
    "\n",
    "for variable in true_bayes_net:\n",
    "        \n",
    "    if variable.id == 0:\n",
    "        variable_parents = []\n",
    "    elif variable.id == 1:\n",
    "        variable_parents = [_A_] # list can be converted in tuple then\n",
    "    elif variable.id == 2:\n",
    "        variable_parents = [_A_,_H_]\n",
    "    elif variable.id == 3:\n",
    "        variable_parents = [_A_, _S_]\n",
    "    elif variable.id == 4:\n",
    "        variable_parents = [_C_, _S_] # later in function maximum_likelohood_estimate the variables get sorted\n",
    "    \n",
    "    P_est = maximum_likelihood_estimate(data=train, variable_id=variable.id, parent_ids=tuple(variable_parents), alpha=0)\n",
    "    \n",
    "    if variable.id == 0:\n",
    "        A = P_est\n",
    "    elif variable.id == 1:\n",
    "        H_A = P_est\n",
    "    elif variable.id == 2:\n",
    "        S_AH = P_est\n",
    "    elif variable.id == 3:\n",
    "        C_AS = P_est\n",
    "    elif variable.id == 4:\n",
    "        V_CS = P_est\n",
    "    \n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H_A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S_AH.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C_AS.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V_CS.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_3 =  log_likelihood(data=train, bayes_net=bayes_net_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0745ab2383ea7481c0124edd4c68cd3a",
     "grade": true,
     "grade_id": "cell-0847b76132961219",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_3 < -8500\n",
    "assert tr_log_likelihood_3 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "857888c7d2f49620bad82ddd5f1c4a6e",
     "grade": false,
     "grade_id": "cell-60eaec1dda1e7b09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Train Log-Likelihoods\n",
    "\n",
    "Compare the log-likelihoods w.r.t the training data of Model **M1** (having the true underlying structure) to the two models our medicine freshman came up with (**M2** - no edges, **M3** - complex model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae46f32357d5c58a722e4046bf08c6f0",
     "grade": false,
     "grade_id": "cell-14898c94ac010e16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(train|M1) = -8508.579282438383\n",
      "logP(train|M2) = -8740.033479010004\n",
      "logP(train|M3) = -8504.427454360399\n"
     ]
    }
   ],
   "source": [
    "print('logP(train|M1) = {}'.format(tr_log_likelihood_1))\n",
    "print('logP(train|M2) = {}'.format(tr_log_likelihood_2))\n",
    "print('logP(train|M3) = {}'.format(tr_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f3d168c63f1925ef3830ddedcb83a1d",
     "grade": false,
     "grade_id": "cell-c6cc8633bf6db812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question in one sentence! (1 point)\n",
    "</div>\n",
    "\n",
    "Even though **M1** has the true underlying network structure (it correctly represents all independencies holding in our world), it doesn't have the highest train log-likelihood. How do you explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be344344394f67f5fe02c21d744f98f0",
     "grade": true,
     "grade_id": "cell-f239713a903eec15",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The complex model covers all true edge relations and in addition two edges which are connected to the involved nodes by estimating P(X|Y) such that it delivers some kind of related information and also the dataset is only an estimation of the ground truth which can't be perfectly represented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d13109a2ded58f6791d74d33bcf58b2",
     "grade": false,
     "grade_id": "cell-913efb638a138834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Test Log-Likelihoods\n",
    "\n",
    "Finally, we compute the test log-likelihood of the model **M1** (having the true underlying structure) and the models our medicine freshman created **M2** and **M3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce2d838d52c5ec2698eecbf58224ce14",
     "grade": false,
     "grade_id": "cell-7405d51a161fef12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(test|M1) = -8376.49246068484\n",
      "logP(test|M2) = -8598.449646741903\n",
      "logP(test|M3) = -8379.468463963516\n"
     ]
    }
   ],
   "source": [
    "te_log_likelihood_1 = log_likelihood(test, bayes_net_1)\n",
    "te_log_likelihood_2 = log_likelihood(test, bayes_net_2)\n",
    "te_log_likelihood_3 = log_likelihood(test, bayes_net_3)\n",
    "\n",
    "print('logP(test|M1) = {}'.format(te_log_likelihood_1))\n",
    "print('logP(test|M2) = {}'.format(te_log_likelihood_2))\n",
    "print('logP(test|M3) = {}'.format(te_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ae32b8fdf28f130ec9a18281101d16d",
     "grade": false,
     "grade_id": "cell-305b267f209685e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question! Keep your answers short! (1 point)\n",
    "</div>\n",
    "\n",
    "What is the difference w.r.t. the log-likelihoods of the training data? Explain the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d059bd7ea2f45258367e174a11b3d48c",
     "grade": true,
     "grade_id": "cell-b53213b16dfb15f6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "For case of the training data the model the model was already trained on it. It seems to be overfitting the case as the models explain the test set better than the training set. Visibile becomes that through the higher log-likelihood values by using the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "108780d815a7ecd7f8abcdff0e1c185f",
     "grade": false,
     "grade_id": "cell-513dda62c8ee6d5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Laplace Smoothing\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question! Keep your answer short! (1 point)\n",
    "</div>\n",
    "\n",
    "Our medicine freshman wants to estimate the (conditional) probability tables for her model **M3** again. However, this time she only has a training set consisting of 100 samples. She runs into the error shown in the output of the code cell below. Explain to her, what the source of the problem is and how she can avoid it by adapting a parameter when calling the function ```maximum_likelihood_estimate```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52567a2a99156b1ec48da9aa7d140464",
     "grade": true,
     "grade_id": "cell-256e320984be291c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "By calculating the P(X|Y) estimate with formula (N[X,Y]/N[Y]) it can happen that some values of Y simply don't exist in the dataset such that the denominator becomes 0 and we end up with nan values in the P(X|Y) estimates. Therefore, alpha has to be bigger than zero which is an input of the maximum_likelihood_estimate function such that we have P(X|Y) estimate of form (N[X,Y]+alpha)/(N[Y]+alpha*number_of_possible_X_values). Through that the denominator doesn't become 0 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a93e59b572cf30a59ec6f759bd5c5add",
     "grade": false,
     "grade_id": "cell-b49ffaae7f446e67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6576/4013883794.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cpdt = (cpdt_counter+alpha)/(denominator+alpha*2) # the 2 represents \"k\", the number of possible\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Probabilities on axis 0 have to sum to 1!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m C_AS \u001b[38;5;241m=\u001b[39m maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n\u001b[1;32m      9\u001b[0m V_CS \u001b[38;5;241m=\u001b[39m maximum_likelihood_estimate(train, _V_, (_S_,_C_,))\n\u001b[0;32m---> 11\u001b[0m bayes_net_3 \u001b[38;5;241m=\u001b[39m \u001b[43mBayesNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_A_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_H_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_A_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_AH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_S_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_A_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_H_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mC_AS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_C_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_A_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_S_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_CS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_V_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_C_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_S_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Schreibtisch/ProbabilisticModels/k01234567/bayesian_network.py:120\u001b[0m, in \u001b[0;36mBayesNet.__init__\u001b[0;34m(self, resampling_distribution, *pdt_ids_tuples)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(structure)\u001b[38;5;241m.\u001b[39missubset(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_nodes))), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid node ID in table descriptor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Node IDs must be in range(num_nodes) ( < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdt_ids_tuples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Tuple: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdt,\u001b[38;5;250m \u001b[39mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(pdt) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability Density Table has to be a NumPy ndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    119\u001b[0m                                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but was of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pdt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misclose(pdt\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbabilities on axis 0 have to sum to 1!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pdt\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    122\u001b[0m     structure), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of table dimensions has to match \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    123\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe number of Variable indices (1 (self) + n_parents)!\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    124\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN-Dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdt\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != Len(Idcs): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(structure)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Order PDT dimensions by variable id\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Probabilities on axis 0 have to sum to 1!"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# we generate a new training set consisting of 100 samples for our medicine freshman\n",
    "train = sample_forward(true_bayes_net, 100)  \n",
    "\n",
    "A = maximum_likelihood_estimate(train, _A_)\n",
    "H_A = maximum_likelihood_estimate(train, _H_, (_A_,))\n",
    "S_AH = maximum_likelihood_estimate(train, _S_, (_A_, _H_,))\n",
    "C_AS = maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n",
    "V_CS = maximum_likelihood_estimate(train, _V_, (_S_,_C_,))\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
