{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxYE5JcM4UpT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<!-- Assignment 6 - SS 2023 -->\n",
    "\n",
    "# Normalising Flows (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06IIOZ1z4UpV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook contains one of the assignments for the exercises in Deep Learning and Neural Nets 2.\n",
    "It provides a skeleton, i.e. code with gaps, that will be filled out by you in different exercises.\n",
    "All exercise descriptions are visually annotated by a vertical bar on the left and some extra indentation,\n",
    "unless you already messed with your jupyter notebook configuration.\n",
    "Any questions that are not part of the exercise statement do not need to be answered,\n",
    "but should rather be interpreted as triggers to guide your thought process.\n",
    "\n",
    "**Note**: The cells in the introductory part (before the first subtitle)\n",
    "perform all necessary imports and provide utility functions that should work without (too much) problems.\n",
    "Please, do not alter this code or add extra import statements in your submission, unless explicitly allowed!\n",
    "\n",
    "<span style=\"color:#d95c4c\">**IMPORTANT:**</span> Please, change the name of your submission file so that it contains your student ID!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkfyb2HN4UpW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this assignment, we take a look at the change of variables formula\n",
    "for distributions and how it can be used to train a generative model.\n",
    "These generative models are known as normalising flows,\n",
    "and make it possible to do density estimation with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE2c3k1q4UpX",
    "outputId": "f218f660-40d3-44ea-bc2b-26e449cbb736",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "torch.manual_seed(1806)\n",
    "torch.cuda.manual_seed(1806)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_c_gDdiT4UpZ",
    "outputId": "4de81347-2f50-45bd-b1ae-bc976f1f79dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "gdrive/MyDrive/.pytorch\n"
     ]
    }
   ],
   "source": [
    "# google colab data management\n",
    "import os.path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    _home = 'gdrive/MyDrive/'\n",
    "except ImportError:\n",
    "    _home = '~'\n",
    "finally:\n",
    "    data_root = os.path.join(_home, '.pytorch')\n",
    "\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ALd80-Ma4Upa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_to_image(*data: torch.Tensor,\n",
    "                  means: tuple = (0, ), stds: tuple = (1., )) -> Image:\n",
    "    \"\"\"\n",
    "    Convert multiple tensors to one big image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data0, data1, ... dataN : torch.Tensor\n",
    "        One or more tensors to be merged into a single image.\n",
    "    means : tuple or torch.Tensor, optional\n",
    "        Original mean of the image before normalisation.\n",
    "    stds : tuple or torch.Tensor, optional\n",
    "        Original standard deviation of the image before normalisation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image : Image\n",
    "        PIL image with all of the tensors next to each other.\n",
    "    \"\"\"\n",
    "    # concatenate all data\n",
    "    big_pic = torch.cat([x for x in data], dim=-1)\n",
    "\n",
    "    means = torch.tensor(means)\n",
    "    stds = torch.tensor(stds)\n",
    "    to_image = transforms.Compose([\n",
    "        # inverts normalisation of image\n",
    "        transforms.Normalize(-means / stds, 1. / stds),\n",
    "        transforms.Lambda(lambda x: torch.clamp(x, 0, 1)),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    return to_image(big_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k2ftdBGp4Upb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NormalisingFlowTrainer:\n",
    "    \n",
    "    def __init__(self,\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        optimiser: optim.Optimizer,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : torch.nn.Module\n",
    "            Neural Network that will be trained.\n",
    "        criterion : torch.nn.Module\n",
    "            Loss function to use for training.\n",
    "        optimiser : torch.optim.Optimizer\n",
    "            Optimisation strategy for training.\n",
    "        tracker : Tracker, optional\n",
    "            Tracker to keep track of training progress.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimiser = optimiser\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\" Current state of learning. \"\"\"\n",
    "        return {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"objective\": self.criterion.state_dict(),\n",
    "            \"optimiser\": self.optimiser.state_dict(),\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict: dict):\n",
    "        \"\"\" Restore learning state. \"\"\"\n",
    "        self.model.load_state_dict(state_dict[\"model\"])\n",
    "        self.criterion.load_state_dict(state_dict[\"objective\"])\n",
    "        self.optimiser.load_state_dict(state_dict[\"optimiser\"])\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        \"\"\" Device of the (first) model parameters. \"\"\"\n",
    "        return next(self.model.parameters()).device\n",
    "\n",
    "    def _forward(self, data: DataLoader, metric: callable):\n",
    "        \"\"\" Unsupervised variation on forward propagation. \"\"\"\n",
    "        device = self.device\n",
    "\n",
    "        for x, _ in data:\n",
    "            x = x.to(device)\n",
    "            outputs = self.model(x)\n",
    "            res = metric(outputs)\n",
    "            yield res\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, data: DataLoader, metric: callable) -> list:\n",
    "        self.model.eval()\n",
    "        results = self._forward(data, metric)\n",
    "        return [res.item() for res in results]\n",
    "\n",
    "\n",
    "    @torch.enable_grad() \n",
    "    def update(self, data: DataLoader) -> list:\n",
    "        self.model.train()\n",
    "        errs = []\n",
    "        for err in self._forward(data, self.criterion):\n",
    "            errs.append(err.item())\n",
    "            self.optimiser.zero_grad()\n",
    "            err.backward()\n",
    "            self.optimiser.step()\n",
    "        return errs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def display_inverted(self, y: torch.Tensor, \n",
    "                         prior : distributions.Distribution = None):\n",
    "        \"\"\"\n",
    "        Display data using the inverse function of a normalising flow.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        flow : nn.Module\n",
    "            The normalising flow.\n",
    "        y : torch.Tensor\n",
    "            A sample batch from the easy distribution to visualise.\n",
    "        prior : Distribution, optional\n",
    "            The prior distribution for printing the\n",
    "            probability of the generated images.\n",
    "        \"\"\"\n",
    "        x = self.model.invert(y)\n",
    "        if prior is not None:\n",
    "            log_py = prior.log_prob(y).view(len(x), -1).sum(-1)\n",
    "            log_det = flow.log_det_jacobi(x)\n",
    "            log_px = log_py + log_det\n",
    "            print(f\" --- first image info --- \", end='')\n",
    "            print(f\"log-py: {log_py[0]:.1e}, log-px: {log_px[0]:.1e}\")\n",
    "\n",
    "        x_vis = x.view(-1, 1, 28, 28).cpu()\n",
    "        x_im = data_to_image(*x_vis, means=(.1307, ), stds=(.3081, ))\n",
    "        display(x_im, metadata={'width': '100%'})\n",
    "    \n",
    "    def train(self, loader: DataLoader, num_epochs: int = 10, vis_every: int = 5,\n",
    "              prior: distributions.Distribution = None):\n",
    "        \"\"\"\n",
    "        Train a normalising flow for a number of epochs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loader : DataLoader\n",
    "            A data loader for iterating over batches of the data.\n",
    "        num_epochs : int, optional\n",
    "            Number of times to iterate the dataset.\n",
    "        vis_every : int, optional\n",
    "            Frequency, during training, of \n",
    "            intermediate visualisation of generated samples.\n",
    "        prior : Distribution, optional\n",
    "            The prior distribution for the normalising flow (for visualisation).\n",
    "        \"\"\"\n",
    "        dev = self.device\n",
    "        if prior is None:\n",
    "            try:\n",
    "                prior = self.criterion.prior\n",
    "            except AttributeError:\n",
    "                x, _ = next(iter(loader))\n",
    "                mean = torch.zeros_like(x[0]).to(dev)\n",
    "                std = torch.ones_like(x[0]).to(dev)\n",
    "                prior = distributions.Normal(mean, std)\n",
    "\n",
    "        y_vis = prior.sample((10, )).to(dev)\n",
    "        errs = self.evaluate(loader, self.criterion)\n",
    "        print(f\"Epoch {0:02d} - avg loss: {sum(errs) / len(errs)}\")\n",
    "        self.display_inverted(y_vis, prior)\n",
    "\n",
    "        for i in range(1, num_epochs + 1):\n",
    "            errs = self.update(loader)\n",
    "            print(f\"Epoch {i:02d} - avg loss: {sum(errs) / len(errs)}\")\n",
    "            if i % vis_every == 0:\n",
    "                self.display_inverted(y_vis, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2N9leU84Upd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions and Distributions\n",
    "\n",
    "One of the foundations of normalising flows is the *change of variable* formula,\n",
    "which allows to reason about the effect functions have on distributions.\n",
    "Given a random variable $Y = f(X)$, where $f$ is a bijective function\n",
    "and $X$ is a random variable from a distribution with pdf $p_X$,\n",
    "the change of variable allows us to write down the pdf, $p_Y$,\n",
    "that defines the distribution of $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYkOu-nV4Upe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For a scalar function $f : \\mathbb{R} \\to \\mathbb{R}$,\n",
    "the change of variable formula is given as follows:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "  p_Y(y) = p_X(f^{-1}(y)) \\cdot \\left|\\frac{\\partial f^{-1}(y)}{\\partial y}\\right|.\n",
    "\\end{aligned}$$\n",
    "\n",
    "This formula reveals that the probability density of $Y = f(X)$\n",
    "is proportional to the probability density of $X$.\n",
    "Moreover, the proportion of densities is the gradient of the inverse,\n",
    "or, equivalently, the inverse of the gradient, $f'(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbn880sm4Upf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To gain some intuition for the change of variable formula,\n",
    "it might help to consider the visualisation of the histogram below.\n",
    "Consider inputs distributed according to $X \\sim \\mathcal{U}(0, 2)$,\n",
    "which is illustrated by the histogram below the $x$-axis.\n",
    "To get a feeling for the distribution of $Y = X^2$,\n",
    "we map each bin in the histogram to its corresponding range on the $y$-axis.\n",
    "\n",
    "The *probability densities* are the height of each bin.\n",
    "The area of each bin represents the actual probability,\n",
    "and must be conserved through function application.\n",
    "This means that if a bin on the $x$-axis is mapped to a smaller or larger range,\n",
    "the density on the $y$-axis will proportionally grow or shrink, respecively.\n",
    "Therefore, the change in probability density is proportional\n",
    "to the the change of range due to the function.\n",
    "For infinitesimally small bins, this \"change of range\" \n",
    "eventually corresponds to the derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8XRC4s-4Upg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<figure>\n",
    "  <figcaption style=\"text-align: center\"> Change of Variables through the function $f(x) = x^2$ </figcaption>\n",
    "  <figure style=\"display: inline-block; max-width: 33%; margin: 0;\">\n",
    "    <img alt=\"visualisation of change of variables formula with one histogram bin\" src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0A%3Csvg%20viewBox%3D%220%200%20500%20500%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22200%22%20y1%3D%22320%22%20x2%3D%22200%22%20y2%3D%22300%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22300%22%20x2%3D%22200%22%20y2%3D%22300%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22200%22%20y%3D%22320%22%20width%3D%22100%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22300%22%20y1%3D%22320%22%20x2%3D%22300%22%20y2%3D%22100%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22100%22%20x2%3D%22300%22%20y2%3D%22100%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22150%22%20y%3D%22100%22%20width%3D%2230%22%20height%3D%22200%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cpath%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20fill%3A%20none%3B%22%20d%3D%22M%20200%20300%20C%20233.33%20300%20266.67%20233.33%20300%20100%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%22%20x1%3D%22200%22%20y1%3D%2290%22%20x2%3D%22200%22%20y2%3D%22310%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%22%20x1%3D%22190%22%20y1%3D%22300%22%20x2%3D%22410%22%20y2%3D%22300%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%3C%2Fsvg%3E\" style=\"width: 500px\" />\n",
    "    <figcaption style=\"text-align: center\">(a) 1-bin histogram</figcaption>\n",
    "  </figure>\n",
    "  <figure style=\"display: inline-block; max-width: 33%; margin: 0;\">\n",
    "    <img alt=\"visualisation of change of variables formula with two histogram bins\" src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0A%3Csvg%20viewBox%3D%220%200%20500%20500%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22200%22%20y1%3D%22320%22%20x2%3D%22200%22%20y2%3D%22300%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22300%22%20x2%3D%22200%22%20y2%3D%22300%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22200%22%20y%3D%22320%22%20width%3D%2250%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22250%22%20y1%3D%22320%22%20x2%3D%22250%22%20y2%3D%22250%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22250%22%20x2%3D%22250%22%20y2%3D%22250%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22120%22%20y%3D%22250%22%20width%3D%2260%22%20height%3D%2250%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Crect%20x%3D%22249.96%22%20y%3D%22320%22%20width%3D%2250%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22300%22%20y1%3D%22320%22%20x2%3D%22300%22%20y2%3D%22100%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22100%22%20x2%3D%22300%22%20y2%3D%22100%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22160%22%20y%3D%22100%22%20width%3D%2220%22%20height%3D%22150%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cpath%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20fill%3A%20none%3B%22%20d%3D%22M%20200%20300%20C%20233.33%20300%20266.67%20233.33%20300%20100%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%22%20x1%3D%22200%22%20y1%3D%22310%22%20x2%3D%22200%22%20y2%3D%2290%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%22%20x1%3D%22190%22%20y1%3D%22300%22%20x2%3D%22410%22%20y2%3D%22300%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%3C%2Fsvg%3E\" style=\"width: 500px\" />\n",
    "    <figcaption style=\"text-align: center\">(b) 2-bin histogram</figcaption>\n",
    "  </figure>\n",
    "  <figure style=\"display: inline-block; max-width: 33%; margin: 0;\">\n",
    "    <img alt=\"visualisation of change of variables formula with four histogram bins\" src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0A%3Csvg%20viewBox%3D%220%200%20500%20500%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22200%22%20y1%3D%22320%22%20x2%3D%22200%22%20y2%3D%22300%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22300%22%20x2%3D%22200%22%20y2%3D%22300%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22200.04%22%20y%3D%22320%22%20width%3D%2225%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22225%22%20y1%3D%22320%22%20x2%3D%22225%22%20y2%3D%22287.5%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22287.5%22%20x2%3D%22225%22%20y2%3D%22287.5%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%2260%22%20y%3D%22287.5%22%20width%3D%22120%22%20height%3D%2212.5%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Crect%20x%3D%22225%22%20y%3D%22320%22%20width%3D%2225%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22250%22%20y1%3D%22320%22%20x2%3D%22250%22%20y2%3D%22250%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22250%22%20x2%3D%22250%22%20y2%3D%22250%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22140%22%20y%3D%22250%22%20width%3D%2240%22%20height%3D%2237.5%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Crect%20x%3D%22250%22%20y%3D%22320%22%20width%3D%2225%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22275%22%20y1%3D%22320%22%20x2%3D%22275%22%20y2%3D%22187.5%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22187.5%22%20x2%3D%22275%22%20y2%3D%22187.5%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22156%22%20y%3D%22187.5%22%20width%3D%2224%22%20height%3D%2262.5%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Crect%20x%3D%22275%22%20y%3D%22320%22%20width%3D%2225%22%20height%3D%2260%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22300%22%20y1%3D%22320%22%20x2%3D%22300%22%20y2%3D%22100%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20stroke-dasharray%3A%205px%3B%22%20x1%3D%22180%22%20y1%3D%22100%22%20x2%3D%22300%22%20y2%3D%22100%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%20%20%3Crect%20x%3D%22162.9%22%20y%3D%22100%22%20width%3D%2217.14%22%20height%3D%2287.5%22%20style%3D%22stroke%3A%20rgb%28255%2C%20255%2C%20255%29%3B%20fill%3A%20rgb%2831%2C%20119%2C%20180%29%3B%22%2F%3E%0A%20%20%3Cpath%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%20fill%3A%20none%3B%22%20d%3D%22M%20200%20300%20C%20233.33%20300%20266.67%20233.33%20300%20100%22%2F%3E%0A%20%20%3Cg%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%22%20x1%3D%22200%22%20y1%3D%22310%22%20x2%3D%22200%22%20y2%3D%2290%22%2F%3E%0A%20%20%20%20%3Cline%20style%3D%22stroke%3A%20rgb%280%2C%200%2C%200%29%3B%22%20x1%3D%22190%22%20y1%3D%22300%22%20x2%3D%22410%22%20y2%3D%22300%22%2F%3E%0A%20%20%3C%2Fg%3E%0A%3C%2Fsvg%3E\" style=\"width: 500px\" />\n",
    "    <figcaption style=\"text-align: center\">(c) 4-bin histogram</figcaption>\n",
    "  </figure>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyltwdAl4Uph",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For multi-variable functions, we simply exchange the derivative\n",
    "by the determinant of the Jacobian, which gives:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "  p_Y(\\mathbf{y}) = p_X(g^{-1}(\\mathbf{y})) \\cdot \\left|\\det \\mathcal{J}_g(\\mathbf{y})\\right|^{-1}.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Note that the determinant of the Jacobian corresponds to \n",
    "the change of area due to function application.\n",
    "To gain some intuition for this version of the formula,\n",
    "the visualisations above can be generalised to e.g. 2d histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le_Db0jD4Upi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 1:  Jacobian Check (3 points)\n",
    "\n",
    "To get some feeling for the change of variable formula,\n",
    "an invertible function with easy-to-compute Jacobian determinant has been provided.\n",
    "To make sure that there are no mistakes in the provided module,\n",
    "you can use the `autograd` magic in pytorch to verify its implementation.\n",
    "\n",
    " > Use the automatic differentiation engine of pytorch\n",
    " > to compute the Jacobian of a pytorch module.\n",
    " > The `jacobian` function should compute the Jacobian matrix\n",
    " > of a given module at a given input.\n",
    " > It should work for any PyTorch module, also if inputs and outputs are different!\n",
    " > You should **not** use `torch.autograd.jacobian` (or similar functions)\n",
    " > and your solution should support batched inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "l6dSqqIO4Upi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AffineFunction(nn.Module):\n",
    "    \"\"\" An example of a very simple invertible function. \"\"\"\n",
    "    \n",
    "    def __init__(self, shift: float = 0., log_scale: float = 0.):\n",
    "        super().__init__()\n",
    "        self.shift = shift # b\n",
    "        self.log_scale = log_scale\n",
    "        \n",
    "    @property\n",
    "    def scale(self):\n",
    "        from math import exp\n",
    "        return exp(self.log_scale)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.scale * x + self.shift\n",
    "    \n",
    "    def invert(self, y):\n",
    "        return (y - self.shift) / self.scale\n",
    "    \n",
    "    def log_det_jacobi(self, x):\n",
    "        log_diag_jacobi = torch.full_like(x, self.log_scale)\n",
    "        return torch.sum(log_diag_jacobi, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "id": "GKJCtty54Upj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a21410ea3111f78198d779de78e81eb9",
     "grade": false,
     "grade_id": "cell-6a11370f59c827dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jacobian(func: nn.Module, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian of a function at a given input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : nn.Module (D -> K)\n",
    "        The function to compute the Jacobian for.\n",
    "    x : (N, D) torch.Tensor\n",
    "        Batch of inputs to compute Jacobian for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Jacobian: (N, K, D)\n",
    "        The computed Jacobian determinants.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    needed_shape = func(x[0]).shape[0]\n",
    "    Jacobian = torch.empty((x.shape[0],needed_shape, x.shape[1]))\n",
    "    x.requires_grad=True\n",
    "\n",
    "    # each x:\n",
    "    for ind_x ,single_x in enumerate(x):\n",
    "      out_single_x = func(single_x) # function takes all features of x\n",
    "      out_single_x.requires_grad_()\n",
    "      jacobian_i = torch.zeros(x.shape[0], needed_shape)\n",
    "\n",
    "      # each out:\n",
    "      for ind_out, single_out in enumerate(out_single_x):\n",
    "        one_hot_out_grad = torch.zeros_like(out_single_x)\n",
    "        one_hot_out_grad[ind_out] = 1.0 # single_out gets marked at its gradient position such that in optimization/.backward() only this output is considered\n",
    "\n",
    "        # compute grads:\n",
    "        func.zero_grad()\n",
    "        out_single_x.backward(one_hot_out_grad, retain_graph=True)\n",
    "        jacob_single_x_single_out = x.grad[ind_x] # shape 1xD # the output was computed for a single x which shall be the differentitation tool, therefore mark that x with ind_x\n",
    "        Jacobian[ind_x,ind_out,:] = jacob_single_x_single_out\n",
    "         \n",
    "    return Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0ikf9B3g4Upj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d173c0d4b1bd5c18591335f9e281087",
     "grade": true,
     "grade_id": "cell-3dd63e98f9692394",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "func = AffineFunction(2, 1)\n",
    "x_scalar = torch.linspace(-5, 5, 128).view(-1, 1)\n",
    "j_scalar = jacobian(func, x_scalar)\n",
    "assert j_scalar.shape == (128, 1, 1), (\n",
    "    \"ex1: jacobian output has wrong shape for scalar affine function (-1 point)\"\n",
    ")\n",
    "assert torch.allclose(func.log_det_jacobi(x_scalar).exp(), j_scalar.squeeze()), (\n",
    "    \"ex1: jacobian determinant does not match log determinant of scalar affine function (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "T1Qr7oSb4Upk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05fbe52df291ceb7edf3889b088b10aa",
     "grade": true,
     "grade_id": "cell-6042890dbcd9659a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x_vector = torch.linspace(-5, 5, 128).view(32, 4)\n",
    "j_vector = jacobian(func, x_vector)\n",
    "assert j_vector.shape == (32, 4, 4), (\n",
    "    \"ex1: jacobian output has wrong shape for vector affine function (-1 point)\"\n",
    ")\n",
    "assert torch.allclose(func.log_det_jacobi(x_vector).exp(), torch.det(j_vector)), (\n",
    "    \"ex1: jacobian determinant does not match log determinant of vector affine function (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yoVttHnL4Upk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3162b194b78f87ea29bfec2966d58c38",
     "grade": true,
     "grade_id": "cell-390cb30ce051aefa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "func = nn.Sequential(nn.ELU(), nn.Linear(4, 3))\n",
    "x = torch.linspace(-5, 5, 128).view(32, 4)\n",
    "j = jacobian(func, x)\n",
    "assert j.shape == (32, 3, 4), (\n",
    "    \"ex1: jacobian output has wrong shape for fc layer (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEi5Jbtm4Upl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 2: Change of Variables (2 points)\n",
    "\n",
    "With an invertible module like `AffineFunction`, \n",
    "implementing the change of variables formula should not be too hard.\n",
    "\n",
    " > Implement the `cov_pdf` function to compute the probability density\n",
    " > of the image of a function using the change of variables formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "id": "0chJaQgR4Upl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43921551b524f9924fe160900d053ee5",
     "grade": false,
     "grade_id": "cell-98d0f1ee74179d96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def cov_pdf(y: torch.Tensor, func: nn.Module,\n",
    "            x_dist: distributions.Distribution):\n",
    "    \"\"\"\n",
    "    Compute the probability density using the change of variables formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : (N, D) torch.Tensor\n",
    "        Batch of values to compute probability density for.\n",
    "    func : nn.Module\n",
    "        The invertible function in the change of variables formula.\n",
    "    x_dist : Distribution\n",
    "        The distribution of the inputs. # e.g. normal distribution N(-1,1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p_y : (N, ) torch.Tensor\n",
    "        Probability density for each value in the batch.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # compute |det J_g(y)|^(-1) (= |det J_(g^(-1))(y)|):\n",
    "    jacobian_y_det = torch.exp(func.log_det_jacobi(y))\n",
    "    second_part = 1/abs(jacobian_y_det) # shape N \n",
    "    \n",
    "    # compute p_x(g^(-1(y))):\n",
    "    out_inv = func.invert(y)\n",
    "    first_part = torch.exp(x_dist.log_prob(out_inv)) # probability density for x_dist's inputs\n",
    "    first_part = torch.prod(first_part, dim=1) # for each sample multiply all its dimension probabilities to get probabilty for a multidimensional distribution\n",
    "\n",
    "    # compute aim p_y(y):\n",
    "    py = first_part * second_part\n",
    "\n",
    "    return py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NOjyD4E24Upm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c8f0a6f5fffaf26538114c065c17fbb",
     "grade": true,
     "grade_id": "cell-815dbe698a8e505a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "func = AffineFunction(2, 1)\n",
    "z_gauss_1d = distributions.Normal(0., 1.)\n",
    "ref_gauss_1d = distributions.Normal(func.shift, func.scale)\n",
    "\n",
    "x_scalar = torch.linspace(-1., 1., 128).view(128, 1)\n",
    "p_cov = cov_pdf(x_scalar, func, z_gauss_1d)\n",
    "assert torch.allclose(p_cov, ref_gauss_1d.log_prob(x_scalar).exp()[:, 0]), (\n",
    "    \"ex2: cov_pdf outputs incorrect density for 1d affine function (-0.5 points)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-hHzDHQH4Upn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1b8e74515a6e36b2539516060574040",
     "grade": true,
     "grade_id": "cell-54e8d5064fad93aa",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "by2MDT9c4Upn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f03bc2c776247ec35f9ef021b687f2e",
     "grade": true,
     "grade_id": "cell-544804d07b354ef7",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j9Qe4WAb4Upo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b4a02f006557cb519584931431b7cb5",
     "grade": true,
     "grade_id": "cell-e83430f16162ca87",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "func = AffineFunction(2, 1)\n",
    "z_mean, z_std = torch.zeros(4), torch.ones(4)\n",
    "z_gauss_4d = distributions.Normal(z_mean, z_std)\n",
    "ref_mean, ref_cov = z_mean + func.shift, func.scale ** 2 * torch.eye(4)\n",
    "ref_gauss_4d = distributions.MultivariateNormal(ref_mean, ref_cov)\n",
    "\n",
    "x_vector = torch.linspace(-1., 1., 128).view(32, 4)\n",
    "p_cov = cov_pdf(x_vector, func, z_gauss_4d)\n",
    "assert torch.allclose(p_cov, ref_gauss_4d.log_prob(x_vector).exp()), (\n",
    "    \"ex2: cov_pdf outputs incorrect density for 4d affine function (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eliIrkwp4Upp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Normalising Flows\n",
    "\n",
    "Given some input distribution and an invertible function,\n",
    "the change of variables formula gives the distribution of the outputs.\n",
    "Equivalently, it can be used to get the distribution of the inputs,\n",
    "given the output distribution:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "  p_X(\\mathbf{x}) = p_Y(g(\\mathbf{x})) \\cdot \\left|\\det \\mathcal{J}_g(\\mathbf{x})\\right|.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Instead of fixing the invertible function in the formula, \n",
    "it is also possible to fix the input and output distributions.\n",
    "With this mindset, the change of variables formula\n",
    "provides a way to learn a function that is able to\n",
    "transform one distribution to some other distribution.\n",
    "\n",
    "Normalising flows are parameterised invertible functions\n",
    "that can be used to learn a function that can transform a distribution.\n",
    "More concretely, they map a complex data distribution, $X$,\n",
    "to some very simple target distribution, $Y$.\n",
    "To make normalising flows a practical generative model, \n",
    "two key entities should be easy to compute:\n",
    " 1. the inverse: \n",
    "    To generate new data, we sample from the simple distribution \n",
    "    and use the inverse of the normalising flow to transform it \n",
    "    to a sample in the data distribution.\n",
    " 2. the (log-)determinant of the Jacobian:\n",
    "    Normalising flows are trained to maximise the likelihood (see below),\n",
    "    which can be computed using the change of variables formula.\n",
    "    The logarithm stems from the fact that the log-likelihood\n",
    "    has some practical advantages over the plain likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIhJ_bf24Upp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 3: Invertible Networks (5 points)\n",
    "\n",
    "Neural networks are in general not (easily) invertible,\n",
    "and therefore not suited for normalising flows.\n",
    "One solution is to make use of so-called *coupling layers*.\n",
    "A coupling layer simply splits its inputs in two parts\n",
    "and computes the two parts of the outputs separately.\n",
    "One part of the output is simply one of the input parts.\n",
    "This input part is also used as input to a *conditioner network*.\n",
    "The conditioner network computes the parameters for an invertible transformation\n",
    "that is used to compute the second part of the output from the other input part.\n",
    "\n",
    " > Implement the `AdditiveCoupling` module below\n",
    " > so that it implements an invertible coupling layer.\n",
    " > Use $\\tau(x\\mathbin{;}\\theta) = x + \\theta$ for the invertible transformation.\n",
    " > Apart from the forward pass, you will also need to implement\n",
    " > the inverse function and the logarithm of\n",
    " > the absolute determinant of the jacobian.\n",
    " \n",
    "**Hint:** You want to make sure that the identity-part of the coupling does not always operate on the same pixels (when stacking multiple coupling layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "id": "1eeBbCh44Upq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bea594eb8b9c87f1d5759870a379103",
     "grade": false,
     "grade_id": "cell-2cf1cb4f6c389fb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdditiveCoupling(nn.Module):\n",
    "    \"\"\" Coupling layer with additive coupling law. \"\"\"\n",
    "    \n",
    "    def __init__(self, sub_net: nn.Module):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        sub_net : nn.Module\n",
    "            The sub network to use as conditioner.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conditioner = sub_net\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" Compute forward pass + log determinant of jacobian. \"\"\"\n",
    "        y = self._forward(x) \n",
    "        ldj = self.log_det_jacobi(x)\n",
    "        return y, ldj\n",
    "    \n",
    "    def _forward(self, x): \n",
    "        \"\"\" Convert inputs to outputs. \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # info: https://sebastiancallh.github.io/post/affine-normalizing-flows/\n",
    "\n",
    "\n",
    "        if x.shape[1] % 2 != 0: # x number features odd\n",
    "          x = x[:,:-1] # remove last feature to make number features even\n",
    "          # because we have T = x + theta the both x parts x_part1 and x_part2 need to have the same size as x relates to x_part2 and theta to x_part1\n",
    "\n",
    "        d = int(x.shape[1]/2)\n",
    "\n",
    "\n",
    "        x_part1 = x[:,:d]\n",
    "        x_part2 = x[:,d:]\n",
    "\n",
    "        out_part1 = x_part1\n",
    "        conditioner_out = self.conditioner(x_part1)\n",
    "        theta = conditioner_out \n",
    "        out_part2 = x_part2 + theta \n",
    "\n",
    "        out_reversed = torch.cat((out_part2, out_part1),axis=1)\n",
    "\n",
    "        return out_reversed\n",
    "        \n",
    "    def invert(self, y):\n",
    "        \"\"\" Convert outputs to inputs. \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        if y.shape[1] % 2 != 0: # x number features odd\n",
    "          y = y[:,:-1] # remove last feature to make number features even\n",
    "          # because we have T = x + theta the both x parts x_part1 and x_part2 need to have the same size as x relates to x_part2 and theta to x_part1\n",
    "\n",
    "        d = int(y.shape[1]/2)\n",
    "\n",
    "        out_of_part2 = y[:,:d]\n",
    "        x_part1 = y[:,d:]\n",
    "\n",
    "        theta = self.conditioner(x_part1)\n",
    "        x_part2 = out_of_part2 - theta\n",
    "\n",
    "        x = torch.cat((x_part1, x_part2),axis=1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def log_det_jacobi(self, x):\n",
    "        \"\"\" Compute logarithm of Jacobian determinant. \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # jacobian is triangular and therefore the diagonal determines its determinant. As we have for y_part2 dx/dx=I and for y_part1 d(x+theta)/dx=I which build combined \n",
    "        # together the diagonal on the jacobian, we get as jacobian's determinant 1. --> log(1)=0 --> sum over all features 0 = 0. Therefore, return 0 for every sample x:\n",
    "        return torch.zeros((x.shape[0])).to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Iegbwj0E4Upq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d37a660f736361fbff99bc791ca2514",
     "grade": true,
     "grade_id": "cell-04a9d578925ae1fb",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = torch.ones(7, 40)\n",
    "func = AdditiveCoupling(nn.Linear(20, 20))\n",
    "y = func._forward(x)\n",
    "assert y.shape == (7, 40), (\n",
    "    \"ex3: AdditiveCoupling._forward method produces outputs with incorrect shape (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yGviuu1z4Upr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "484861d9cb0c7fe174c8184ab58549ec",
     "grade": true,
     "grade_id": "cell-5420a7bdd34dbdc1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RxDvtPw04Upr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f30090e4c32c086f53d8d61a888d44e0",
     "grade": true,
     "grade_id": "cell-6fa5332df473d4c3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cqJG2nz84Upr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdafc89fd4600366b773696727aa7fb2",
     "grade": true,
     "grade_id": "cell-41740b225594dd00",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "round_trip = func.invert(y)\n",
    "assert round_trip.shape == (7, 40), (\n",
    "    \"ex3: AdditiveCoupling.invert method produces outputs with incorrect shape (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Hr-AJVvh4Ups",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4dd15bb12885062db39f8721d76c37b",
     "grade": true,
     "grade_id": "cell-a86cf32f8f21b964",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert torch.allclose(x, round_trip), (\n",
    "    \"ex3: AdditiveCoupling.invert does not implement inverse operation (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PTvYfuDI4Ups",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e3cc42c7d13ca4faa792621d1b4e625",
     "grade": true,
     "grade_id": "cell-39fc4ce6867a8aa1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "R8u-T7kc4Upt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0e1f89b68a1680f836206c4127ecd90",
     "grade": true,
     "grade_id": "cell-022de385dfc7da01",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ALsNmcE14Upt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "873d6de04df357dc2baf96b8c716930a",
     "grade": true,
     "grade_id": "cell-42dce0bfd889565d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = torch.ones(7, 40)\n",
    "ldj = func.log_det_jacobi(x)\n",
    "assert ldj.shape == (7, ), (\n",
    "    \"ex3: AdditiveCoupling.log_det_jacobi produces output with incorrect shape (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "x5wcqwq64Upu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a00883236bbe7797171b52cc408f721",
     "grade": true,
     "grade_id": "cell-ca3cc0898c9afaf7",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axFcTFEW4Upu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 4: Likelihood Maximisation (3 points)\n",
    "\n",
    "Adding the parameters of the normalising flow \n",
    "in the change of variable formula, gives the following expression\n",
    "\n",
    "$$\\begin{aligned}\n",
    "  p_X(\\mathbf{x} \\mathbin{;} \\mathbf{w}) = p_Y(g(\\mathbf{x} \\mathbin{;} \\mathbf{w})) \\cdot \\left|\\det \\mathcal{J}_g(\\mathbf{x} \\mathbin{;} \\mathbf{w})\\right|.\n",
    "\\end{aligned}$$\n",
    "\n",
    "This is exactly the probability of the data, \n",
    "given the parameters, or the *likelihood*, of the normalising flow.\n",
    "By maximising this likelihood, we obtain the function\n",
    "that is most likely to be the true transformation to go from $X$ to $Y$.\n",
    "Note that maximising the likelihood is equivalent to \n",
    "minimising the negative logarithm of the likelihood.\n",
    "This gives us the objective for training a normalising flow.\n",
    "\n",
    " > Complete the implementation of the `NegativeLogLikelihood` module\n",
    " > to compute the *negative log-likelihood* for a normalising flow.\n",
    " > Use the `reduction` method to combine the results \n",
    " > from multiple samples in a batch.\n",
    " > Also, distinguish between sample density and pixel densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "id": "fYErlDat4Upv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5a41f5cd5c9e0fd55682761473a5abb",
     "grade": false,
     "grade_id": "cell-6562fb16638c07ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NegativeLogLikelihood(nn.Module):\n",
    "    \"\"\" Negative Log-Likelihood of normalising flow. \"\"\"\n",
    "    \n",
    "    def __init__(self, prior: distributions.Distribution,\n",
    "                 reduction: str = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        prior : Distribution\n",
    "            The output distribution of the normalising flow.\n",
    "        reduction : str, optional\n",
    "            How to aggregate results for multiple samples in a batch.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.prior = prior\n",
    "        \n",
    "        if reduction is None or reduction == 'mean':\n",
    "            self.reduction = torch.mean\n",
    "        elif reduction == 'sum':\n",
    "            self.reduction = torch.sum\n",
    "        elif reduction == 'none':\n",
    "            self.reduction = lambda x, **kwargs: x\n",
    "        else:\n",
    "            raise ValueError(f\"unknown reduction: '{reduction}'\")\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        \"\"\" \n",
    "        Compute negative log-likelihood on batch of NF outputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        outputs : ((N, D) torch.Tensor, (N, ) torch.Tensor)\n",
    "            Batch of outputs from the normalising flow. # which is the CoupleLayer output\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        nll : torch.Tensor\n",
    "            The aggregated negative log-likelihood for this batch. \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        y, log_det_jacob = outputs\n",
    "       \n",
    "        neg_log_like = - self.prior.log_prob(y) - log_det_jacob.reshape(-1,1) \n",
    "        neg_log_like = torch.mean(neg_log_like,dim=1) # take the mean of the single pixel probability densities\n",
    "        nll = self.reduction(neg_log_like,dim=0) # reduce along the samples\n",
    "\n",
    "        return nll\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jHLogYvc4Upv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76234d6cb1edfd50ba84653c4aae5178",
     "grade": true,
     "grade_id": "cell-efb16f1bcd52c794",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete\n",
    "y = torch.randn(3, 10)\n",
    "nll = NegativeLogLikelihood(distributions.Normal(0., 1.), reduction=\"none\")\n",
    "loss = nll((y, torch.ones(len(y))))\n",
    "assert loss.shape == (3, ), (\n",
    "    \"ex4: NegativeLogLikelihood produces outputs with wrong shape for none reduction (-1 point)\"\n",
    ")\n",
    "assert torch.all(loss > 0), (\n",
    "    \"ex4: NegativeLogLikelihood produces non-positive outputs for steep function (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YfcQugGj4Upw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ce534207882a3bc982431812fe2d3a7",
     "grade": true,
     "grade_id": "cell-5f61fbf778a4e4ab",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete\n",
    "nll = NegativeLogLikelihood(distributions.Normal(0., 1.), reduction=\"mean\")\n",
    "loss = nll((y, torch.ones(len(y))))\n",
    "assert loss.shape == (), (\n",
    "    \"ex4: NegativeLogLikelihood produces outputs with wrong shape for mean reduction (-0.5 points)\"\n",
    ")\n",
    "nll = NegativeLogLikelihood(distributions.Normal(0., 1.), reduction=\"sum\")\n",
    "loss = nll(func(x))\n",
    "assert loss.shape == (), (\n",
    "    \"ex4: NegativeLogLikelihood produces outputs with wrong shape for sum reduction (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cMkCnSE24Upw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af8c73ea3e3f66e994d8fb77c12c6cd6",
     "grade": true,
     "grade_id": "cell-529cd1fa030aa420",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete\n",
    "nll1 = NegativeLogLikelihood(distributions.Normal(0., 1.))\n",
    "nll2 = NegativeLogLikelihood(distributions.Normal(0., 2.))\n",
    "assert torch.any(nll1((y, torch.ones(len(y)))) != nll2((y, torch.ones(len(y))))), (\n",
    "    \"ex4: NegativeLogLikelihood ignores prior (-0.5 points)\"\n",
    ")\n",
    "assert torch.any(nll1((y, torch.ones(len(y)))) != nll1((y, torch.zeros(len(y))))), (\n",
    "    \"ex4: NegativeLogLikelihood ignores log_det (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QcsmK-L04Upy",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4e239725dd903408a17c75a4f36371b",
     "grade": true,
     "grade_id": "cell-f7442c301f442343",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w90vc6y84Upy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 5: Training a Normalising Flow (2 points)\n",
    "\n",
    "With the invertible network layers and objective function,\n",
    "we have everything we need to train a normalising flow.\n",
    "Since multi-layer networks are more powerful,\n",
    "you will find the `NormalisingFlow` class below useful.\n",
    "\n",
    " > Construct a normalising flow with multiple coupling layers.\n",
    " > Each coupling layer should have a multi-layer conditioner.\n",
    " > The training results should produce reasonably looking images.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RawLNkwU4Upy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NormalisingFlow(nn.Sequential):\n",
    "    \"\"\" Sequence of invertible layers, forming a normalising flow. \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" Compute forward pass + log determinant of jacobian. \"\"\"\n",
    "        ld = 0\n",
    "        for m in self:\n",
    "            x = m._forward(x)\n",
    "            ld = ld + m.log_det_jacobi(x)\n",
    "        return x, ld\n",
    "    \n",
    "    def _forward(self, x):\n",
    "        \"\"\" Convert inputs to outputs. \"\"\"\n",
    "        for m in self:\n",
    "            x = m._forward(x)\n",
    "        return x\n",
    "    \n",
    "    def invert(self, y):\n",
    "        \"\"\" Convert outputs to inputs. \"\"\"\n",
    "        for m in reversed(self):\n",
    "            y = m.invert(y)\n",
    "        return y\n",
    "    \n",
    "    def log_det_jacobi(self, x):\n",
    "        \"\"\" Compute logarithm of Jacobian determinant. \"\"\"\n",
    "        ld = 0\n",
    "        for m in self:\n",
    "            ld = ld + m.log_det_jacobi(x)\n",
    "        return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "id": "8g9G96jo4Upz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "516ca7ed903ddf3efa2da62ab6d2fb72",
     "grade": false,
     "grade_id": "cell-4db693123b3f560a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_multi_flow(num_in: int = 784):\n",
    "    \"\"\"\n",
    "    Create a normalizing flow with multiple multi-layer coupling layers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_in : int\n",
    "        Number of input neurons.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    conditioner = nn.Sequential(\n",
    "    nn.Linear(num_in//2, 1400),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(1400, 1100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(1100, 800),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(800, num_in//2)\n",
    "    )\n",
    "\n",
    "    whole_net = NormalisingFlow(AdditiveCoupling(conditioner),AdditiveCoupling(conditioner),AdditiveCoupling(conditioner),\n",
    "    AdditiveCoupling(conditioner),AdditiveCoupling(conditioner))\n",
    "\n",
    "    return whole_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5-BccJGg4Upz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b942aea8a6600d9dd3eafffae2302c",
     "grade": true,
     "grade_id": "cell-43a8db84156bfb9f",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "flow = build_multi_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sBY8beEd4Upz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56b26ac6707a2cb1656fac2ac8193c40",
     "grade": true,
     "grade_id": "cell-c06adb2fe1eaf778",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xqBG6pCf4Up0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39416f9ff309fc64f233f1953003f55f",
     "grade": true,
     "grade_id": "cell-39f58ba2eb83f077",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = torch.randn(3, 784)\n",
    "y = flow._forward(x)\n",
    "assert y.shape == x.shape, (\n",
    "    \"ex5: build_multi_flow does not produce outputs with correct shape (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "O3SlPHPO4Up1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "pre_process = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.1307, ), (.3081, )),\n",
    "    nn.Flatten(0)\n",
    "])\n",
    "mnist = datasets.MNIST(data_root, transform=pre_process)\n",
    "loader = DataLoader(mnist, batch_size=128, shuffle=True)\n",
    "\n",
    "# objective\n",
    "mean = torch.zeros(784).to(device)\n",
    "std = torch.ones(784).to(device)\n",
    "prior = distributions.Normal(mean, std)\n",
    "nll = NegativeLogLikelihood(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "mPwqfThv4Up2",
    "outputId": "adc1a9e2-bc7e-40a6-e3c1-54df9d8cf7f0",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 - avg loss: 1.4233818199080446\n",
      " --- first image info --- log-py: -1.1e+03, log-px: -1.1e+03\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAAAAACfA//yAAAXJElEQVR4nC2ZaVQbhpXvf0IICZAEaENsEgIkIRBCCyCQhFgFYhP7voPZF4PBLDZ4t7FjvBs7cbwkdhLHTpw4SbOdpGmSpk06M23SdJtOk76emb7TTjtnzkznnfPOe29meB/c+/l+uP97zj3/3/lfWI/AT508KTE8h2Q9idwvhlzSvoqRF3xQ2L6ZWMQwBX69ZRbbWqT++9m1YAZ4irI1XKsv0AqA4o9bsMNpOfQABBzjb1LF6rwE9JwGKK6Zu0BCWsUPabHVnm3AShPsj0LvjqCdsPTOzbO5ufJIpcJ1TzsA/MqF9+iwvDG6VKgtq7QXnGgxdXG6un49E0ikBxesAVaQMj7GWxuEkxCfhjnM43gu0oY+APhjCxNgGW2GpC2R2BRFhle7gsltSZTVVhrpwwBAIQNjPuO3VzX7iE9PXYB6/Q8h5NTD9Iw3ISyiBnObOItLLn7TXtLwX5xG2ZvdbXZo2isFIPabKILnE1vr0x46H+FTxADso4iLD1Yw8RIJPmE1wRisN+41WeCAlPqi2MGThwq7fLdQ+04hM34SXgOOaU4A2Za5a397pBDoZpmyXrCg+LyIRYZT2imAgjD8bsE+yjqDHDc1VB4OW8yP+akEeQnwDi11EL40DnjJ+YkUP/ksXqFRVhtRhrGUolN3XJyIaKaKKpBXwGYCaMEGJGriAPIRsQNaSFf+kwf3j+pHANKRrXeKSEDZn2q51+ZuucEAgLmyIN1U1JzVEaqadgA4IEqblkXzzajIAoDZJPihWsKgBE75wVScALXs2oip2EN2Uk/PmfSxK0Ies8tY9seW43w8qJKOUQV74a6lBbpYIfZ54ot1KcuPDjHGCFzIJb9wsK6RWjhMBfYJIzkL6lK/GDVLmVtJ7la8oJYA4Jb1WyrfKoWs8U8jABhOJfeie+eqtBd8qjwAqhmnoYvjsf9XV9pLde+RW5CC4thBeqF95gFMdQZ/b6sIT7qqTj3NHp6UTEcGcGAfVKpZoZdVkxZDZMce7sxAkBZYZ/opT7UThpxOJ0oV9Gtskd9MZNTN18z1k3KmQRlJl/ALrGoOGchCR+bepWr4Oys9wVrW9w2n9YPoO/JBqRF3ExhhCqQ3HUsVflHaYFOVbQXJ61GCCgVEKwyNGQj3Phlxyflrywo6MZNzM+3z7BLDZUA+CQzL0TPJ2edAjmuBaqRyoDuDNSBJMsWFp+tzJSoCbeDcrT327M4T0WHCAUc6+sydiLFt6soXDnZ4VEz3q+FN4gEhYwmxU1fCzdJLPOAM1cNjUuI/BUBfwGYK2TqV9n5Sejv7oM2u3Ooyz2n+8HT1VaTICh83O3uxTZ2sAzYvzSCzHjNAbTXJfFv890WN4+AFMu1d+rlmOMYvfUAHAEMzQDWXUruozD765wX0zwZABTsG/1QedLPftZDxyZsSkGr7610iGGprOp7R2PaUZ5i5gSPNvA4u+XwTRk42RkZlZBOgX20cHM2iA9AY4HgUmsuzf97CE4DfeqELQX8qnn15EMS84qmvgHjA7T3GazxWLJdvkgRJcZyw6nY2/FRC9oQ9H0TGDtx5oZhIRwyryKT2AR5B/Y9lcNRr/+JZ2O+ZRwVoI4knk0BgAuAc1QAFyiBccw7nz/gVqFRq8cEMB67ixJ56xqoSVRm2/I32IGT++t5VqAaUSLuBrr7Up4EMG/ZiQGQm7mndchv8u3yM8y/R5J+3oUes6/M2vRpZLlDmXoIOV/lkxV0Yycp5FrL/kFUP0AtUUccZiEywBxuhnP7A0VGWLpDqLgOjGhk5FJN23LnQ1eamiX4Z9CcgQsRNIpCrpOvAv7X45ti0LqZiYBvAm/8iqTp7TXdcOzOIZI6+Dy0U2eN45zm57bd9K1eAcAPduUB1q/mzXurkNz0UrKOGowft3VRoADOvzoHr+1HUn7ZDS6vy46pd5q08e5xyHWnRJzdpK+L9vQBZB1pdYh6UxPWVQ/b+0o8AHgVvb7USBTieakgnGQqCo11P7Gh8JDgpoLaH5g3aCBd2UNq7VaL9XVN5WwzJDb/kHAg+U5DKD5WA0/4Ttim5UEqBmtrbjgPJBwQHAb3FvPaSPd01T7cB+rMBmIm7Gt9byFM5K14EdT1Pa+LyI57Y8c9Ra19P5k4lgzRQ5zYIW81Fb/O3ZDa7NgAsEdtU7ynheYzHfOLpnlSAYlzKSZL6phaJ46R7f539Fy8wBiioW2Vq5F9InVYKcwVwpmQyHpTn8DY0kAI3FXuALbLm7L4Mc8wGgKcYEfTABwizphe684Co/94aSqDrqZQ3JjLRGnTb4Ho3gBw3S9AaFjNIKtXPAMjgbC3P15jP5V4d4kQciCmvKc35ureOm69gP/tPEauWLC6WdTPQ/abRmdnFMjbQrUMK1VJatUUdww7AfBosQA6I40iCySBEhRL+d5j5+AO0gI/URIjay0PU+0+twb6cPy300sTwugQyPxK5liCyboUh4EqIKZ26ribXTai0BMyVUYpV8JRK2Sq+m9HFSSDvLs3E5kVq2H8k7BsO5kNOOr24ujhBoEJbEcNg1RUy+JDKjkoT48SnQYC94CeRPmzXWFKXSmNHye+modcCQ34zD2koZOIrpsgVNLbsZlYnMQCuQmMLWYsRAjiTZwboWRnqzMfyPxrjiRbYXMXowODch+eNU3nmE8qF0jdIydCA4bo9osqF7N/RNHMSLSqwRY7MklMfyevNvlL8suqoA/RxBU0WZKUzc39/VRaqZdZ9Fu0nz1SH+jGWGGoHGKmp0OGAQTk4ZSqA/C4bCZXkXMRLVTxoy9lAiBa0qxW03mutvgD5sUg81mbazc8UR78S2QxSz+yqCbj3KRcrvZXb3xETIWgDQRoEsvCkw2YlXTS73z0P0BgN/C4ehNdNxp3Ea1vhS0Dl78QvsLFjap5zLc5igxyIT68t3uZEXXya9zZ6/05ctP9FIoEI3yMgBhdBRNJmJJO8S516VIHggsxBtWNGDUC6RJOWb8ikseeNqNQFcFDDyN2fWR5o3y92sh1uWOWRXJXS3XHW/WFrChDxF/t0PDgdkMbXMIma3mEYoxBqM+mQGGIp8q5VcsBOMdHOnBkwmmEWYo4jXwOyJ+KTrQP44E+IiRZ7pvju4xB3q+Q5iYWkn+i8btfgujffRpRC2AWjoxx23O/TBPM5jpnSTNhtlDdPvi+aSm2mmw7UYtjthV1t0EUSNUCF7Qm0zDO/PbgYMxniBSZB/s3X5Dh5hMoMIAUfCWjLivYyMKotgl2QnSB88HYbJRPl2uhZ2A+2KPhRLCxxHixakkVkQ7m4sjmZ0jpnu94IdxRcNjUB6qruLF5BQuQTStxwFy3XIcIa6NCB6D8QIi5igxhfyU4AIUF3CM0HIjBDLdMAah/cbkoyKa6Ccxj3YKQPcl5FgySgaw9Ra6q42b6E/sfyoeWR2CRcNYAvHkpk66ymx1j5LLOgk8816PXmWRRDlTYKGIABHO3rQDRKLWHo0NTW5tVFZSN4GGdvwZnDAXGTQniy7tmJoWcOymKw3Ydrw7RlmW6+Al6Y/myki1wKS0HnV+dfgwcYN7RzMbuMyghXhaEof5gyc9VhAT1kFtJnzH/Btls+tQhKgO7t1ihepKFdXZEoOUEkiY8J8LItSUP4AgKHh8Giq5LnAXiIlyZg/so3LfnOOJDhXgwwvtTWHyP2Fu490JiyXTCcFDhHFH9ouIaHKOfkIgwijgv1MpaR4QrWO3wIVIyk5oilrhFYyF4EZQzdhMWtMcVyHI0x4+dcKblWDtMNE6jEqVN++XA8cGRMKKzlk6HDM/jhCBceC8h19PBJUm6Fguddi7G4fBYaH+gacYZlA+hABExEJhiAEPELsp5qFlQo3ylrNwKukR0IBzJSbWX9Wpw0EvklZH4J7YAAcOgypHVaYkHrCelbAeLN76d3ff6ESvmtjZzE+2EiSs5W0oj+H4Ghj45Sqfnmrx2sNkQDDGDE56L0OeqQhpRMNxfzN0QThJL35VxL1wB15JTDRROgS72/7/8FPn9PvEULDLVmSNrT0qjpkHPu6GqaMfzS6Bx9sZC/P89dz/QNJrED+XCK9FsBMTc6iBUBSZnUEm98E7iH0nfXA5WEA2czoaqM7L52wtYO+vKB/xlpSrYYuehf2kdqAihyjhKnMN+f6okI9t+y3mQf9BiSKerhIkow78SNgtN6aWWYMYjumlX2+NmzUJPrrml87Wg7wWaEnQ2Qa6y4cUxckPrZu2peOItS6OP1pOqfY83rAT7g0KGFfWWt3wUHyBYJ5LxfX0JiAjirfCrRKvzq983Z3UXHkMSTQ4yhGaDbezSfU2C7OgHwW7YM3LS4eFckAI0GBXx/LS1U8b1ACaXWRJiFgx7KhKjCqE6fH/yZSvV25cJQO3o6wD55ihNsgOqYmew++PFWKwySuCwhFQl1//w+wmOjA4dPQpdZATBRMSAluaYeVwfgy4TaNYsdVWNIWIrpNaiCPhusa0mrJAQEurwNBNIHCo/weo9a4QER6PgVsPFUe676PDP8eK/UYnBDELhxGIwk5nu+ExsbAJjzB6lhfY1+4RBOekoZJQYFeKjiPPBan/u0OjwtBmbPmXQR4RQ8grB1tR4rmmtvwhgJVFyjAWE2zFHRmE6nCNIdM5ACFfGlYEc8WhZ9bFbOGTR3gNMNLGoo0BJ+kUmXYyTi7PBz8TVETpSKo0g97qlloodaXSS6lgIATJcQsuj88G0T9PfbhUBBe0k5hIA9kGaocBY1sGbF4pe1gI86l8pOG6j67LnTfaLwKLKiUXINQy4wFoZFErxEkAXy4JxROhg6cuRbIRLNprKMU7HFyY3kkrnBs59tBnwfEgV6ZQdLC6Yk/HAH/X6gBHpueXgogmwdgWIojaBoG9MMQ4SPCLN9nUN95wibIRtolVHBitWCyxlNN02F7MMNbF6Gh8C3BewZ1SAA4ND1NFJAM/5v8WFEZ3fyAye5Q1kFQEPFXaaAKvcTu+NmHYYH9BwCfRMwW8o/QC0Nqt7zQC5RC0soWlLEbVchPDbVTsWtxXowAVeKWlC2to5rkRX+Z2sUvHVhGO8qvAgqlxORI3+IqhKN0dD0M05tt/MJ9BVi6XfGUx4C+UvAYDNAW8qf4P6el1eauqeU4cC8IzgGrxOi8aI2Bhzl5um30Q8GKK4kJFk8GOyFCv0duEKBASvEkEmmYKzsXDpyMkCNrVE+kcU87Ge+kvVL/7lKXpia4vK5S5h1wGXL5YzvMmICE7tZ/V8NFj3KAuEuKJP+AlFfkGUZtRIBrQo+vhCbTjuscOpnhA9VE6LRbZKAta1V1K5DaOgFanKYTeON1ygqVA6Dar4UUwJQ7/qqVVPDREo9B5QJ95fwiCk5RH7rPhnsKbHYbl0XCQ+DdgdQ9G+q4ZUS4eh5nZdxW8byr9rxET527jAZSW8rcLi0R0K6Cw1VtihvDdcsgG6INwexA3moqTzvrXzETIniBskLe6DW/AHFGHM4Bc1zACgvM59P1y/rrpqzt1KhheJKwA1fzSQQ4ebkxWSHaZ4ehJAaIJlpkvgLjZNba/doNTVxM/CAAgl287m9ynG6UslTBu05wJW3gNafvF1G5Hb0T/Uiuo+CsI74U7svxZ70aq3ZLR2pbCQQq+aAQb05biMlE77VYNaV5ci95aQ/XnmuK8Lo4WmaErildIZpcrhlx7WZWYvA2WRjjh/5Mz4ml4+fDpKL2m7gv1V52RroPw6DzooNcjdABUDLR9TDqgxB1hmTt5c6pMFkTleRhsdKAzJ06VXsfDB2PI+uSVEdLHSp/tXmvc5glA04RtVRo0/giSvkJSYo+IIv1C/v2Rd3E6++gYr9tPLWsPRId6U2w5Z53kkhsIHr5TqAcWAt7cUpgJoeG5uw3KDpnplcLyhNIO1wXMHEmPBVshJ0mclMZCigYIflL8Ohsh61gmkKEzEfZIEpg3AXNKRZTDF69vM1AlKbj0m5yqo7GqCEpUPktsDrv8g4DAkP4U/IiY/UxHoCV+h6THoRoP0FrryEvwPeiarDiIUXDmGCcOQngBU4jXmMEB7csVtFhduCEqAkwyApKIt67id/5Ql3UJEsI8fbMKKjJSiZXG0qPoCxteHhAZ+RY734lIUX71qSWwvRtUANEUqiskARQgA4p0DCA2DlvXj7YgNZEOlF33CbCsYAaouTumEsSL42W5lfdnuZbUpN7MX70/V5CLpWxpzPpqXXD7isY55D4n1AEqQBKAACGZ2Na6cDay3bFVEBnvHPyTwr+D8qvURB+Lj2SjzMN/USDe/RBOzAi+QBo+SijPJzlKGD1eWMN66UUFso3m3upudFXdzdIiKIw14EaubQLX2vzmXSAXG3aR8GK95v0ewhJvHJmiIJsmdmJaqjBk1UD5gwMwbRkKYUXWSl3ZxgLzRljRxQeCL47KVCwilijp3MfqSLpLbsogaER13Q3o6CkwFWyACQVFU/DMEo+KGzDuDre5lrE2Qf5m1eZyOXnLa/l4E7wbZT/X/wz+w5Y4REhsnEV34G53dABsnipE5OBAJoJxK43Hyaub5dUPuqr4BAmwXGksgsju5WjLBQqrUcXCJE3VPkjGb4u83e5bAO/ecX05PA/HKBVFcbXBLDI1VYkg8v7gbQTY+wGR3x9hnDrpA0wYuXHybW7/KYiOEFnkuO3YRPq7OLcRT4LZ2rU4CEtMa02TLZiTmui5jxnwT4IPr89wDMENdKXARs65ByQbIXJ+wNcHxI0IgrACCDgeZINHlA555M860igLxQfmcgHCocLwtAD8q+wZ7fZOdTFBck3kjJ15/HevmN+SSRItGIgjt3FkEQTspw3kYfGpriSCiyhnIBrAexqstUgIUmIHO5FCDVOmHDEAxnNpBBeXvYyU4A9muYMSE+Sy55M2KGcyaruuj/dJBeiAfRBu49yGHxeERYZg+1/DEGECcx7EjcmiTqb243ZZW5vZklAGyUTkIhISYRSbshpj0E/2tL3Vl+JJ36jZZAMwUGOffw3AlRuJc/R1LGP6CBGZm28K/HW5ohHeUzawebACVGhviR+ujnbR80C/AxlbucYMVZCD6MNOge2OaG5dSFi5ss1pYyVw88H6LBBbj7SYbrv9CVgxXxmDd3DaB+ECBLprrBqXu/iSvtAOvx6lFgLzH0N4OF55FgoksKkuo9vtLyto3PfUkHSd7ivicUOpycghQCX0E42ev0jwuWEbwAX5I1z2kbFeDqm2Qq6RTVI0igefgNuEAYuyzrs9Ffsr76ROtl6r8nFgBhRVVtd4jpgMWrNwyBgwAuIIF3elsW/stU0XA7oYwxoukFSIj340jjenPfV8ruEn4ObLDBAZqhDglQ7wVbK/X7dQ2p9c2VyVr6qIGmMQnXorhx6TxcieDiffiPjhD5frinxI8YG+9AvE76A2bzz5w0OxNhs0qAjhSIZOHofj3xANqXgDSGQAzaSuaTVvsLa4Hfk+VTuFi10PEesIz2p2UA/mfoJnnUoyoA2Cw8ki8i2IyX8kqM2XDtMO3tBxxjnbwwS01DeftwDGwAc5FA5QDcA9jF8Q7hsIXwlaukhXGrn75Tu3U4CJvJTTxyE7ipL3v3uU2s/4omki5yjblV8N5MVEgH+ljahjHu5Uk4CSXLWGmuduBz+ItwvXUjgjndFOBRFVqgH/oyGrDwDMY4maeQrgFANMiRBkJsy4SHodiDjnBI9d6+sAQ9vCsf6IH4qweAgyf1T94gRRSDheEdBsAreYbHTVA14AU35P5Ad52V6dJ4Mvk18BSV/0hRSekGLTZDj3kKmOe6YOcSuI4gIRE3ZVw8QAoBE1TOI8wn8xCzqOHyGmFG3RuwuRZs/9IzYS2kzc56j9QZAD6MiUxcEJ8wlveyY6DewLdLRIdLiVklT7APvYrLFLe29uFOkQN7eYCRPwKtjINhuz6OSRPkQ1HG3v8PSgT8gFvjBJMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28 at 0x7EFC838F56C0>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - avg loss: 1.0721035794154414\n",
      "Epoch 02 - avg loss: 0.993846537080655\n",
      "Epoch 03 - avg loss: 0.9769717867948862\n",
      " --- first image info --- log-py: -1.1e+03, log-px: -1.1e+03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28 at 0x7EFC7D4AEEF0>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 - avg loss: 0.9684108658385938\n",
      "Epoch 05 - avg loss: 0.9629997097607106\n",
      "Epoch 06 - avg loss: 0.9589746317375444\n",
      " --- first image info --- log-py: -1.1e+03, log-px: -1.1e+03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28 at 0x7EFC7D4ACFD0>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 - avg loss: 0.9559950383741465\n",
      "Epoch 08 - avg loss: 0.9534739402057265\n",
      "Epoch 09 - avg loss: 0.951651025174269\n",
      " --- first image info --- log-py: -1.1e+03, log-px: -1.1e+03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28 at 0x7EFC7D4AEEF0>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow = build_multi_flow().to(device)\n",
    "trainer = NormalisingFlowTrainer(\n",
    "    model=flow,\n",
    "    criterion=nll,\n",
    "    optimiser=optim.Adam(flow.parameters(), lr=1e-3)\n",
    ")\n",
    "\n",
    "trainer.train(loader, num_epochs=9, vis_every=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
