{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Assignment 5 - SS 2023 -->\n",
    "\n",
    "# Adversarial Training (13 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains one of the assignments for the exercises in Deep Learning and Neural Nets 2.\n",
    "It provides a skeleton, i.e. code with gaps, that will be filled out by you in different exercises.\n",
    "All exercise descriptions are visually annotated by a vertical bar on the left and some extra indentation,\n",
    "unless you already messed with your jupyter notebook configuration.\n",
    "Any questions that are not part of the exercise statement do not need to be answered,\n",
    "but should rather be interpreted as triggers to guide your thought process.\n",
    "\n",
    "**Note**: The cells in the introductory part (before the first subtitle)\n",
    "perform all necessary imports and provide utility functions that should work without (too much) problems.\n",
    "Please, do not alter this code or add extra import statements in your submission, unless explicitly allowed!\n",
    "\n",
    "<span style=\"color:#d95c4c\">**IMPORTANT:**</span> Please, change the name of your submission file so that it contains your student ID!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will play around with adversarial techniques in deep learning.\n",
    "The main goal is to build some understanding of *Generative Adversarial Networks* (GANs).\n",
    "However, we will also take a look at *adversarial training*,\n",
    "which is a collection of methods for fooling neural networks.\n",
    "Although both approaches are completely unrelated,\n",
    "it turns out that is possible to build GANs, starting from adversarial examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:36.282265Z",
     "iopub.status.busy": "2023-05-30T18:52:36.281800Z",
     "iopub.status.idle": "2023-05-30T18:52:39.184168Z",
     "shell.execute_reply": "2023-05-30T18:52:39.183169Z",
     "shell.execute_reply.started": "2023-05-30T18:52:36.282225Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "\n",
    "torch.manual_seed(1806)\n",
    "torch.cuda.manual_seed(1806)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:39.186940Z",
     "iopub.status.busy": "2023-05-30T18:52:39.186098Z",
     "iopub.status.idle": "2023-05-30T18:52:39.194592Z",
     "shell.execute_reply": "2023-05-30T18:52:39.193512Z",
     "shell.execute_reply.started": "2023-05-30T18:52:39.186903Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.pytorch\n"
     ]
    }
   ],
   "source": [
    "# google colab data management\n",
    "import os.path\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    _home = 'gdrive/MyDrive/'\n",
    "except ImportError:\n",
    "    _home = '~'\n",
    "finally:\n",
    "    data_root = os.path.join(_home, '.pytorch')\n",
    "\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:39.196882Z",
     "iopub.status.busy": "2023-05-30T18:52:39.196446Z",
     "iopub.status.idle": "2023-05-30T18:52:39.218198Z",
     "shell.execute_reply": "2023-05-30T18:52:39.217196Z",
     "shell.execute_reply.started": "2023-05-30T18:52:39.196849Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseTrainer:\n",
    "\n",
    "    def __init__(self,\n",
    "         model: nn.Module,\n",
    "         criterion: nn.Module,\n",
    "         optimiser: optim.Optimizer,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : torch.nn.Module\n",
    "            Neural Network that will be trained.\n",
    "        criterion : torch.nn.Module\n",
    "            Loss function to use for training.\n",
    "        optimiser : torch.optim.Optimizer\n",
    "            Optimisation strategy for training.\n",
    "        tracker : Tracker, optional\n",
    "            Tracker to keep track of training progress.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimiser = optimiser\n",
    "        \n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\" Current state of learning. \"\"\"\n",
    "        return {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"objective\": self.criterion.state_dict(),\n",
    "            \"optimiser\": self.optimiser.state_dict(),\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict: dict):\n",
    "        \"\"\" Restore learning state. \"\"\"\n",
    "        self.model.load_state_dict(state_dict[\"model\"])\n",
    "        self.criterion.load_state_dict(state_dict[\"objective\"])\n",
    "        self.optimiser.load_state_dict(state_dict[\"optimiser\"])\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        \"\"\" Device of the (first) model parameters. \"\"\"\n",
    "        return next(self.model.parameters()).device\n",
    "\n",
    "    def _forward(self, data: DataLoader, metric: callable):\n",
    "        device = self.device\n",
    "        for x, y in data:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = self.model(x)\n",
    "            res = metric(outputs, y)\n",
    "            yield res\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, data: DataLoader, metric: callable) -> list:\n",
    "        self.model.eval()\n",
    "\n",
    "        results = self._forward(data, metric)\n",
    "        return [res.item() for res in results]\n",
    "\n",
    "\n",
    "    @torch.enable_grad()\n",
    "    def update(self, data: DataLoader) -> list:\n",
    "        opt = self.optimiser\n",
    "        self.model.train()\n",
    "\n",
    "        errs = []\n",
    "        for err in self._forward(data, self.criterion):\n",
    "            errs.append(err.item())\n",
    "\n",
    "            opt.zero_grad()\n",
    "            err.backward()\n",
    "            opt.step()\n",
    "\n",
    "        return errs\n",
    "    \n",
    "    @property\n",
    "    def fake_data(self):\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def _display_results(self, count: int = 10):\n",
    "        \"\"\"\n",
    "        Display generated images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        count : int, optional\n",
    "            Number of images to display.\n",
    "        \"\"\"\n",
    "        fake_data = self.fake_data\n",
    "        if fake_data is None:\n",
    "            return\n",
    "        \n",
    "        x = fake_data[:count].to(self.device)\n",
    "        ps = self.model.probabilities(x).view(-1).tolist()\n",
    "        print(\"D probs:\", ', '.join([f\"{p:.2f}\" for p in ps]))\n",
    "\n",
    "        im = data_to_image(*x.cpu(), means=(.1307, ), stds=(.3081, ))\n",
    "        display(im, metadata={'width': '100%'})\n",
    "\n",
    "\n",
    "    def train(self, loader: DataLoader, num_epochs: int = 10, vis_every: int = 5):\n",
    "        \"\"\"\n",
    "        Train an auto-encoder for a number of epochs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loader : DataLoader\n",
    "            A data loader for iterating over batches of the data.\n",
    "        num_epochs : int, optional\n",
    "            Number of times to iterate the dataset.\n",
    "        vis_every : int, optional\n",
    "            Frequency, during training, of \n",
    "            intermediate visualisation of faked samples.\n",
    "        \"\"\"\n",
    "        # evaluate random performance\n",
    "        errs = self.evaluate(loader, self.criterion)\n",
    "        print(f\"Epoch {0: 2d} - avg loss: {sum(errs) / len(errs):.6f}\")\n",
    "        self._display_results()\n",
    "\n",
    "        # train for some epochs\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            errs = self.update(loader)\n",
    "            print(f\"Epoch {epoch: 2d} - avg loss: {sum(errs) / len(errs):.6f}\")\n",
    "\n",
    "            if epoch % vis_every == 0:\n",
    "                self._display_results()\n",
    "        \n",
    "        return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:39.424884Z",
     "iopub.status.busy": "2023-05-30T18:52:39.424543Z",
     "iopub.status.idle": "2023-05-30T18:52:39.430969Z",
     "shell.execute_reply": "2023-05-30T18:52:39.429773Z",
     "shell.execute_reply.started": "2023-05-30T18:52:39.424856Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(logits, targets):\n",
    "    \"\"\"\n",
    "    Compute the accuracy for given logits and targets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    logits : (N, K) torch.Tensor\n",
    "        A mini-batch of logit vectors from the network.\n",
    "    targets : (N, ) torch.Tensor\n",
    "        A mini_batch of target scalars representing the labels.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    acc : () torch.Tensor\n",
    "        The accuracy over the mini-batch of samples.\n",
    "    \"\"\"\n",
    "    correct = torch.argmax(logits, dim=-1) == targets\n",
    "    acc = torch.mean(correct.float())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:40.355439Z",
     "iopub.status.busy": "2023-05-30T18:52:40.355093Z",
     "iopub.status.idle": "2023-05-30T18:52:40.368053Z",
     "shell.execute_reply": "2023-05-30T18:52:40.366775Z",
     "shell.execute_reply.started": "2023-05-30T18:52:40.355408Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_to_image(*data: torch.Tensor,\n",
    "                  means: tuple = (0, ), stds: tuple = (1., )) -> Image:\n",
    "    \"\"\"\n",
    "    Convert multiple tensors to one big image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data0, data1, ... dataN : torch.Tensor\n",
    "        One or more tensors to be merged into a single image.\n",
    "    means : tuple or torch.Tensor, optional\n",
    "        Original mean of the image before normalisation.\n",
    "    stds : tuple or torch.Tensor, optional\n",
    "        Original standard deviation of the image before normalisation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    image : Image\n",
    "        PIL image with all of the tensors next to each other.\n",
    "    \"\"\"\n",
    "    # concatenate all data\n",
    "    big_pic = torch.cat([x for x in data], dim=-1)\n",
    "\n",
    "    means = torch.tensor(means)\n",
    "    stds = torch.tensor(stds)\n",
    "    to_image = transforms.Compose([\n",
    "        # inverts normalisation of image\n",
    "        transforms.Normalize(-means / stds, 1. / stds),\n",
    "        transforms.Lambda(lambda x: torch.clamp(x, 0, 1)),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    return to_image(big_pic)\n",
    "\n",
    "def display_fakes(discriminator: nn.Module, fake_data: torch.Tensor,\n",
    "                  count: int = 10):\n",
    "    \"\"\"\n",
    "    Display the images that are fed as fakes to a discriminator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    discriminator : nn.Module\n",
    "        The discriminator that is to be fooled by the fakes.\n",
    "    fake_data : (N, C, H, W) torch.Tensor\n",
    "        The fake images to display.\n",
    "    count : int, optional\n",
    "        Number of samples to display from `fake_data`.\n",
    "    \"\"\"\n",
    "    device = next(discriminator.parameters()).device\n",
    "    x = fake_data[:count].to(device)\n",
    "    ps = discriminator.probabilities(x).view(-1).tolist()\n",
    "    print(\"D probs:\", ', '.join([f\"{p:.2f}\" for p in ps]))\n",
    "    \n",
    "    im = data_to_image(*x.cpu(), means=(.1307, ), stds=(.3081, ))\n",
    "    display(im, metadata={'width': '100%'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:41.405546Z",
     "iopub.status.busy": "2023-05-30T18:52:41.405169Z",
     "iopub.status.idle": "2023-05-30T18:52:41.418838Z",
     "shell.execute_reply": "2023-05-30T18:52:41.417709Z",
     "shell.execute_reply.started": "2023-05-30T18:52:41.405516Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_attack(attack: callable, network: nn.Module, data: DataLoader,\n",
    "                    loss_func: nn.Module, vis_count: int = 8, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluate an adversarial attack on some data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attack : callable\n",
    "        Function that computes the adversarial example.\n",
    "        Will be called as `attack(x, y, network, loss_func, **kwargs).\n",
    "    network : nn.Module\n",
    "        The network to attack.\n",
    "    data : DataLoader\n",
    "        Data for the attack.\n",
    "    loss_func : nn.Module\n",
    "        Objective for the attack.\n",
    "    vis_count : int, optional\n",
    "        Number of adversarial examples to visualise.\n",
    "    kwargs\n",
    "        Keyword arguments for the attack function.\n",
    "    \"\"\"\n",
    "    dev = next(network.parameters()).device\n",
    "    network.eval()\n",
    "\n",
    "    accuracies = []\n",
    "    for x, y in data:\n",
    "        x, y = x.to(dev), y.to(dev)\n",
    "        adv_x = attack(x, y, network, loss_func, **kwargs)\n",
    "        adv_x = adv_x.clamp(x.min(), x.max())  # put in valid range\n",
    "\n",
    "        # compute accuracy on adversarial examples\n",
    "        with torch.no_grad():\n",
    "            logits = network(adv_x)\n",
    "            acc = accuracy(logits, y)\n",
    "            accuracies.append(acc.item())\n",
    "\n",
    "    print(f\"Adversarial accuracy: {100 * accuracies[0]:.2f}%\")\n",
    "\n",
    "    # collect relevant data\n",
    "    x_ref, y_ref = x[:vis_count], y[:vis_count]\n",
    "    x_adv, y_adv = adv_x[:vis_count], logits[:vis_count].argmax(-1)\n",
    "    with torch.no_grad():\n",
    "        y_pred = network(x_ref).argmax(-1)\n",
    "    \n",
    "    # visualise adversaries\n",
    "    ref_im = data_to_image(*x_ref.cpu(), means=(.1307, ), stds=(.3081, ))\n",
    "    display(ref_im, metadata={'width': '100%'})\n",
    "    print(\"ground truth: \", y_ref.tolist())\n",
    "    print(\"before attack:\", y_pred.tolist())\n",
    "    print(\"after attack: \", y_adv.tolist())\n",
    "    adv_im = data_to_image(*x_adv.cpu(), means=(.1307, ), stds=(.3081, ))\n",
    "    display(adv_im, metadata={'width': '100%'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:42.431311Z",
     "iopub.status.busy": "2023-05-30T18:52:42.430498Z",
     "iopub.status.idle": "2023-05-30T18:52:42.443933Z",
     "shell.execute_reply": "2023-05-30T18:52:42.442974Z",
     "shell.execute_reply.started": "2023-05-30T18:52:42.431269Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiscriminatorTrainer(BaseTrainer):\n",
    "    \n",
    "    def __init__(self, model, criterion, optimiser,\n",
    "                 dataset: \"RealOrFakeDataset\", epsilon: float = 0.1):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : RealOrFakeDataset\n",
    "            The dataset that will be used to train the discriminator.\n",
    "        epsilon: float, optional\n",
    "            The maximum allowed perturbation for the adversarial attacks.\n",
    "        \"\"\"\n",
    "        super().__init__(model, criterion, optimiser)\n",
    "        self.dataset = dataset\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    @property\n",
    "    def fake_data(self):\n",
    "        return self.dataset.fake_data\n",
    "    \n",
    "    def update(self, data: DataLoader) -> list:\n",
    "        results = super().update(data)\n",
    "        self.dataset.update_fake_examples(self.model, self.criterion, self.epsilon)\n",
    "        return results\n",
    "        \n",
    "\n",
    "def train_gan(gan: nn.Module, loader: DataLoader, objective: nn.Module, \n",
    "              optimiser: optim.Optimizer, num_epochs: int = 10, vis_every: int = 5):\n",
    "    \"\"\"\n",
    "    Train a GAN for a number of epochs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gan : nn.Module\n",
    "        The GAN to train\n",
    "    loader : DataLoader\n",
    "        A data loader for iterating over batches of the data.\n",
    "        This can be a standard, \"supervised\" dataloader.\n",
    "    objective : nn.Module\n",
    "        The loss function to optimise during training.\n",
    "    optimiser : optim.Optimizer\n",
    "        The optimiser to use for training.\n",
    "    num_epochs : int, optional\n",
    "        Number of times to iterate the dataset.\n",
    "    vis_every : int, optional\n",
    "        Frequency, during training, of \n",
    "        intermediate visualisation of fake samples.\n",
    "        \n",
    "    \"\"\"\n",
    "    g_errs, d_errs = [], []\n",
    "    for x, _ in loader:\n",
    "        x = x.to(device)\n",
    "        g_errs.append(generator_error(gan, x, objective).item())\n",
    "        d_errs.append(discriminator_error(gan, x, objective).item())\n",
    "    loss_report = ', '.join([\n",
    "        f\"avg G loss: {sum(g_errs) / len(g_errs):.5f}\",\n",
    "        f\"avg D loss: {sum(d_errs) / len(d_errs):.5f}\"\n",
    "    ])\n",
    "    print(f'Epoch {0: 2d}', loss_report, sep=' - ')\n",
    "    fake_data = gan.generator.generate(batch_size=10)\n",
    "    display_fakes(gan.discriminator, fake_data)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        g_errs, d_errs = update_gan(gan, loader, objective, optimiser)\n",
    "        loss_report = ', '.join([\n",
    "            f\"avg G loss: {sum(g_errs) / len(g_errs):.5f}\",\n",
    "            f\"avg D loss: {sum(d_errs) / len(d_errs):.5f}\"\n",
    "        ])\n",
    "        print(f'Epoch {epoch: 2d}', loss_report, sep=' - ')\n",
    "        if epoch % vis_every == 0:\n",
    "            fake_data = gan.generator.generate(batch_size=10)\n",
    "            display_fakes(gan.discriminator, fake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:44.822645Z",
     "iopub.status.busy": "2023-05-30T18:52:44.821662Z",
     "iopub.status.idle": "2023-05-30T18:52:52.478391Z",
     "shell.execute_reply": "2023-05-30T18:52:52.477432Z",
     "shell.execute_reply.started": "2023-05-30T18:52:44.822573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 392957706.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 105152512.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 129630023.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5693523.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /root/.pytorch/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up training (nothing to do here)\n",
    "\n",
    "pre_processing = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.1307, ), (.3081, ))\n",
    "])\n",
    "mnist_train = datasets.MNIST(data_root, transform=pre_processing, download=True)\n",
    "train_loader = DataLoader(mnist_train, shuffle=True, batch_size=128, num_workers=4)\n",
    "\n",
    "mnist_net = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, 4, stride=2),\n",
    "    nn.ELU(),\n",
    "    nn.Conv2d(8, 32, 3, stride=2),\n",
    "    nn.ELU(),\n",
    "    nn.Conv2d(32, 64, 6),\n",
    "    nn.ELU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "trainer = BaseTrainer(\n",
    "    model=mnist_net,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimiser=optim.SGD(mnist_net.parameters(), lr=1e-2, momentum=.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:52:52.480840Z",
     "iopub.status.busy": "2023-05-30T18:52:52.480472Z",
     "iopub.status.idle": "2023-05-30T18:57:23.567242Z",
     "shell.execute_reply": "2023-05-30T18:57:23.565105Z",
     "shell.execute_reply.started": "2023-05-30T18:52:52.480796Z"
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 - avg loss: 2.310794\n",
      "Epoch  1 - avg loss: 0.356059\n",
      "Epoch  2 - avg loss: 0.112316\n",
      "Epoch  3 - avg loss: 0.074124\n",
      "Epoch  4 - avg loss: 0.056325\n",
      "Epoch  5 - avg loss: 0.046636\n",
      "Epoch  6 - avg loss: 0.036963\n",
      "Epoch  7 - avg loss: 0.030945\n",
      "Epoch  8 - avg loss: 0.025034\n",
      "Epoch  9 - avg loss: 0.020623\n",
      "Epoch  10 - avg loss: 0.018712\n",
      "Epoch  11 - avg loss: 0.015201\n",
      "Epoch  12 - avg loss: 0.013424\n",
      "Epoch  13 - avg loss: 0.010467\n",
      "Epoch  14 - avg loss: 0.008822\n",
      "Epoch  15 - avg loss: 0.007537\n",
      "Epoch  16 - avg loss: 0.007254\n",
      "Epoch  17 - avg loss: 0.005839\n",
      "Epoch  18 - avg loss: 0.004752\n",
      "Epoch  19 - avg loss: 0.003479\n",
      "Epoch  20 - avg loss: 0.002577\n",
      "Train accuracy: 99.76%\n",
      "\n",
      "CPU times: user 34.3 s, sys: 8.67 s, total: 42.9 s\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train MNIST classifier\n",
    "errs = trainer.train(train_loader, num_epochs=20)\n",
    "errs = trainer.evaluate(train_loader, accuracy)\n",
    "print(f\"Train accuracy: {100 * sum(errs) / len(errs):.2f}%\")\n",
    "torch.save(trainer.state_dict(), \"mnist_net.pt\")  # for testing\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:23.569598Z",
     "iopub.status.busy": "2023-05-30T18:57:23.569208Z",
     "iopub.status.idle": "2023-05-30T18:57:28.620619Z",
     "shell.execute_reply": "2023-05-30T18:57:28.619331Z",
     "shell.execute_reply.started": "2023-05-30T18:57:23.569555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.06838\n",
      "Eval accuracy: 98.39%\n"
     ]
    }
   ],
   "source": [
    "# test MNIST classifier\n",
    "trainer.load_state_dict(torch.load(\"mnist_net.pt\"))  # for testing\n",
    "mnist_test = datasets.MNIST(data_root, train=False, transform=pre_processing)\n",
    "test_loader = DataLoader(mnist_test, batch_size=len(mnist_test), num_workers=4)\n",
    "errs = trainer.evaluate(test_loader, trainer.criterion)\n",
    "print(f\"Eval loss: {errs[0]:.5f}\")\n",
    "errs = trainer.evaluate(test_loader, accuracy)\n",
    "print(f\"Eval accuracy: {100 * errs[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has become extremely easy to get good models for plenty of tasks.\n",
    "It only takes a few lines of code and a handful of minutes\n",
    "to get a model that is able to recognise handwritten digits.\n",
    "This does not mean, however, that the network *understands* these images.\n",
    "It turns out that even the best models can easily be fooled\n",
    "by creating what is known as *adversarial examples*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are mainly two ways to make a strong network look stupid:\n",
    " 1. Change existing images until the network mis-classifies them,\n",
    " 2. Make predictions on random noise (out-of-distribution images).\n",
    "\n",
    "The first approach is an active topic in Machine Learning research.\n",
    "The main goal is to find the smallest possible perturbations\n",
    "that are required to make the network misclassify its inputs.\n",
    "\n",
    "The second approach can be considered silly because in most cases, \n",
    "a network is simply not able to express that it has no idea what to predict.\n",
    "Nevertheless, this can make systems that rely on neural networks vulnerable.\n",
    "E.g. face recognition software being fooled by carefully constructed noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Projected Gradient Ascent (4 points)\n",
    "\n",
    "One of the easiest ways to construct an adversarial example\n",
    "is to maximise the loss by using gradient ascent on the inputs.\n",
    "After all, the parameters of a neural network are also the result\n",
    "of a gradient descent that minises the loss function.\n",
    "\n",
    "In order to keep the perturbations to the original image small,\n",
    "a constraint is added to the gradient ascent for adversarial examples:\n",
    "the adversarial example must lie in an epsilon-ball around the original input.\n",
    "This procedure is also known as *projected gradient ascent*.\n",
    "\n",
    " > Implement the `adversarial_attack` function below\n",
    " > so that it implements projected gradient ascent as described above.\n",
    " > To speed up the process of finding adversarial examples,\n",
    " > you can use the sign of the gradients instead of the pure gradients.\n",
    " > Make sure not to return the computational graph!\n",
    " \n",
    "**Hint:** If you are having problems with gradient errors, your computations might involve an unwanted gradient flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:28.625239Z",
     "iopub.status.busy": "2023-05-30T18:57:28.624859Z",
     "iopub.status.idle": "2023-05-30T18:57:28.636307Z",
     "shell.execute_reply": "2023-05-30T18:57:28.635058Z",
     "shell.execute_reply.started": "2023-05-30T18:57:28.625206Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e4875cea3c0effa25c0e2d13879171e",
     "grade": false,
     "grade_id": "cell-965f642deb344c0e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adversarial_attack(x: torch.Tensor, y: torch.Tensor,\n",
    "                       network: nn.Module, loss_func: nn.Module,\n",
    "                       epsilon: float = .1, eta: float = .1, steps: int = 10):\n",
    "    \"\"\"\n",
    "    Compute an adversarial example for a network from a given input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        The reference input for the network.\n",
    "    y : torch.Tensor\n",
    "        The label for the reference input.\n",
    "    network : nn.Module\n",
    "        The network to compute the adversary for.\n",
    "    loss_func : nn.Module\n",
    "        The loss function the network was trained with.\n",
    "    epsilon : float, optional\n",
    "        The radius of the ball to keep the adversary within.\n",
    "    eta : float, optional\n",
    "        The step size to use for computing the adversary.\n",
    "    steps : int, optional\n",
    "        The number of gradient steps to take.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    adversary : torch.Tensor\n",
    "        The adversarial example (`x + perturbation`).\n",
    "    \"\"\"\n",
    "    # compute the (delta L/ delta x):\n",
    "    t1 = - epsilon/eta\n",
    "    t2 = epsilon/eta\n",
    "    x.requires_grad = True\n",
    "    \n",
    "    noisy_x = x.clone().detach().to(x.device)\n",
    "    noisy_x.requires_grad = True\n",
    "    \n",
    "    # Optimize:\n",
    "    for _ in range(steps):\n",
    "        _noisy_x = noisy_x.clone().detach().requires_grad_(True)\n",
    "\n",
    "        logits = network(_noisy_x)\n",
    "        logits = logits.squeeze(-1) # make logits comparable to y for the loss_func()       \n",
    "        \n",
    "        loss = -loss_func(logits, y) # loss = - loss as we have gradient ascent instead of gradient descent\n",
    "        loss.backward(retain_graph=False, create_graph=False)\n",
    "\n",
    "        with torch.no_grad():          \n",
    "            gradients = _noisy_x.grad.sign() * eta # it was mentioned that we can only use the sign of gradient\n",
    "            noisy_x -= gradients\n",
    "            \n",
    "        noisy_x = torch.max(torch.min(noisy_x, x + epsilon), x - epsilon)   \n",
    "        noisy_x = noisy_x.clamp_(t1,t2)\n",
    "\n",
    "    return noisy_x.detach()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:28.638171Z",
     "iopub.status.busy": "2023-05-30T18:57:28.637696Z",
     "iopub.status.idle": "2023-05-30T18:57:28.705552Z",
     "shell.execute_reply": "2023-05-30T18:57:28.704521Z",
     "shell.execute_reply.started": "2023-05-30T18:57:28.638137Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "441db99b2bc543eef4c7d63d7134ad28",
     "grade": true,
     "grade_id": "cell-b2294c61854a4e20",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "x = torch.ones(1, 1, 28, 28).to(trainer.device)\n",
    "y = torch.zeros(1, dtype=torch.long).to(trainer.device)\n",
    "x_adv = adversarial_attack(x, y, trainer.model, trainer.criterion, epsilon=0.1)\n",
    "assert x.shape == x_adv.shape, (\n",
    "    \"ex1: adversarial_attack produces outputs with incorrect shape (-1 point)\"\n",
    ")\n",
    "assert torch.abs(x - x_adv).max() <= 0.1 + 1e-5, (\n",
    "    \"ex1: adversarial_attack produces outputs outside of epsilon ball (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:28.707186Z",
     "iopub.status.busy": "2023-05-30T18:57:28.706867Z",
     "iopub.status.idle": "2023-05-30T18:57:28.719965Z",
     "shell.execute_reply": "2023-05-30T18:57:28.719017Z",
     "shell.execute_reply.started": "2023-05-30T18:57:28.707153Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0165b936ec791c00db7ff044301a9140",
     "grade": true,
     "grade_id": "cell-3d16cb2776fe164b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert trainer.model(x_adv)[:, y] < trainer.model(x)[:, y], (\n",
    "    \"ex1: adversarial_attack produces outputs with better results (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:28.722077Z",
     "iopub.status.busy": "2023-05-30T18:57:28.721387Z",
     "iopub.status.idle": "2023-05-30T18:57:28.730128Z",
     "shell.execute_reply": "2023-05-30T18:57:28.729119Z",
     "shell.execute_reply.started": "2023-05-30T18:57:28.722045Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae2aa3da1382493106531c0cf21b2e70",
     "grade": true,
     "grade_id": "cell-29b9974ce8f26df7",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert len(torch.abs(x - x_adv).unique()) <= 5, (\n",
    "    \"ex1: adversarial_attack does not seem to change pixels fast enough (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e6cc9a4a4ed72353da8bf95bb887d55",
     "grade": true,
     "grade_id": "cell-aa15d48e912f0412",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be054fb04a5577496c49d9252760b061",
     "grade": true,
     "grade_id": "cell-716c91d9770e9a69",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5436cd4ec92441f3482e413c7f584253",
     "grade": true,
     "grade_id": "cell-e0c65e7521b2c796",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:28.732127Z",
     "iopub.status.busy": "2023-05-30T18:57:28.731652Z",
     "iopub.status.idle": "2023-05-30T18:57:31.768252Z",
     "shell.execute_reply": "2023-05-30T18:57:31.767237Z",
     "shell.execute_reply.started": "2023-05-30T18:57:28.732063Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy: 51.39%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAFLklEQVR4nO2YbWiVZRjHL3EoR6bgdg6NRoehbuLQcqgg6gSXLqWmmOdEYJDUlyUsdTHShTIxJ6O5jNUsxU2dLo+lk4qB1XzBrXyZsiOEr5uYtjM3NpzOjux+/tfpw85z9Dz39TxZYfrB/6fr/K775bqe+/0QPdMzPdUa8mjFPnC95KOtv+x5vME8OQUAALjstS+SwQUiH1GF0w7Vng4FAPxWcQhYY1/mDeN1kacrheWiJ+ta1Mh9wabNPF4+VIOeY6Vppj0qL8E+okfX1AEE0xJp2DmU2xfa1CdiT5NtgqtDUePzfXKTyTeYXVY4umsgYNqjrvalW9wjvzgu5uw7XLN11ji5H8pTwRQiWhPGHJsSRJP6qyT8/hGlFAIF2bor4YSZ4LLgCLHNxcx7rXuEuxGVsR+f4F2Le+k1IFlqq52Zua85qv1T473eJCKiIBwS9PFsCUMppaDU1Smaa55RGrVWGR6p7rAzzAusMBeIFc7kA4nx3tQuBuqShMZyVs1fVXuDrzPzwB/M0lQsCqNZmzAxnW6XRqEhAgBd7QCsrkndl8zojskJTmMesDLPV1hm2pkhfsvi3gIG0Fs4TA5ydM7InJycmZ5ufk93vhZGSBwkIiJK44sCnd0GpVRlXnaJUvkW377wtKiVFIGYYCnzD1ZWG2mJfch8rrZ4vX1oPQwglGIbKBHREgSFQS4BttjXeZtP6DAtpKCulrmIvB3q7sq4xe+7c940N6NR3BeaODzZynbju2hZ14YebVYs4uM0/J0rHDklzVJTnluRJTo99CdqEnVsqpzzdJiuFH52ExFRgYIa+7AvYJizJK1zIEdqcgZzjwZ3A0frc3Nzczc2AQGr149FRNQAPuoQKq3n3okaTOnCrbFC4aim95wdrtN0pU5Fz3jvyfgER103TLPUOE+SVjB/rMEpNwEGAAauaAHVYzsRdYE32YdKM++zsKc3A5sdKn0U2SvQ9AdbS9rpCB6+53mM2K+A8bXYZi33pup09Jwy7iwrK5sI7NKcfrSO99epHu7OtI91I/+kr4iFYTQ6jfo3vFig5UqZpnWKulrMde6BfA+YZXC7Q49j+Jy+MyX1goHD4y7iS9uKrrPhGRpMPuk8gCmdFyR8yUzQMzuk0BF3Iw0Yv/r9fv/6PScMQ9iziRYxb3PocifmCXTu7Qh/NpxKud12Pa3lBh2WAtYjNU4fco2EYwluUUq1xU/8CfvvGYZhdIaUYYinay33TpP4oPzclyXxudUViUSuemH+DupVdXu6TsOA48mylSskbCbY0KaU0o60LJ/P5yPaZRhaRSJKNTjo0GM1S4s+pjfxu3xQJLdxnYDDQKbb7XYnUILbnV5VVVUZ/9FvsrjRXwYWLLgJRCDcZEytM4xJAvYzb7BPgEL94gCaGlKHtRIfeob1vZeIwoPPQez7tC5qFT/szlZygiuVMu+iqlIqQERUIueez11u+wTyudPeSUQ0+R4yBJzB0nlNdBAPdD8cDhQVxc3jzXxWf7YRkbcjmmBH41jbW+w6eYrWc4vDU68VOyjR8RldyN/qXXqvcaH8F0ZRcXFxHYDtxcUTNKfrAq+We8muGExQfg8OapPRL9CE89zkUKkV25a22O0jRETkucwvanAj81Sh7N8pofmQ7fjMP6gOvDLf6Vt3dq8Q6NBq3ulQqRWMbXb/AwzKq29D2Xf+XYL/Td+Ly5ee3+E07NlHSp6zeRLF9GO/9TqzmvnK+H8S29Otke0LiYjiVnLw5d4nE8zj0N0xTzqC/0d/ASF/lO0b1n1bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x28>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth:  [7, 2, 1, 0, 4, 1, 4, 9]\n",
      "before attack: [7, 2, 1, 0, 4, 1, 4, 9]\n",
      "after attack:  [7, 2, 7, 0, 9, 7, 8, 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x28>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "trainer.model.requires_grad_(False)  # disable parameter gradients\n",
    "evaluate_attack(adversarial_attack, trainer.model, test_loader, trainer.criterion, epsilon=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fooling a Dummy Network\n",
    "\n",
    "Adversarial examples are considered an analysis tool\n",
    "that can help to gain insights in how neural networks behave.\n",
    "However, when pushing these methods, it turns out that\n",
    "adversarial examples can actually also be used to generate new images.\n",
    "The key point to getting useful images, is to attack the right model.\n",
    "\n",
    "Consider the task of predicting whether an input is *real* or *fake*.\n",
    "A *real* sample would be defined as an input that comes from the dataset,\n",
    "whereas a *fake* example is an input that does not appear in the dataset.\n",
    "It should be relatively easy to build a binary classification model for this task.\n",
    "Let us denote this model as a *discriminator*,\n",
    "since it discriminates between *real* and *fake* images.\n",
    "\n",
    "By using an adversarial attack on this model \n",
    "*fake* inputs can be altered to look more like *real* samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:31.772925Z",
     "iopub.status.busy": "2023-05-30T18:57:31.772594Z",
     "iopub.status.idle": "2023-05-30T18:57:31.785418Z",
     "shell.execute_reply": "2023-05-30T18:57:31.784299Z",
     "shell.execute_reply.started": "2023-05-30T18:57:31.772898Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Network for deciding whether a MNIST image is real or fake. \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 4, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(8, 32, 3, stride=2),\n",
    "            nn.ELU(),\n",
    "            # (old-school) global average pooling\n",
    "            nn.Conv2d(32, 64, 6),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def probabilities(self, x):\n",
    "        \"\"\"\n",
    "        Compute probability of inputs being real.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The inputs to compute the probabilities for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : torch.Tensor\n",
    "            Values between 0 (fake) and 1 (real).\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Gradient computations are disabled.\n",
    "        \"\"\"\n",
    "        logits = self.model(x)\n",
    "        return torch.sigmoid(logits)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Make a hard prediction on fake or real.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The inputs to compute the prediction for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : torch.Tensor\n",
    "            Either 0 (fake) or 1 (real).\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Gradient computations are disabled.\n",
    "        \"\"\"\n",
    "        logits = self.model(x)\n",
    "        return (logits > 0).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###### Paradox of the Discriminator\n",
    "\n",
    "If we compute adversarial examples for the discriminator,\n",
    "we can only get more *fake* inputs,\n",
    "since the adversaries are not part of the dataset.\n",
    "Now, a successful adversary of a *real* input,\n",
    "should be classified as a *fake*, and vice versa.\n",
    "Note that successful adversaries of *real* inputs \n",
    "will be **correctly** classified as *fake*.\n",
    "Hence, the obtained example would not really be adversarial.\n",
    "Therefore, the only truly adversarial examples for this model\n",
    "are *fake* inputs that are converted to be recongised as *real*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Discriminator Data (3 points)\n",
    "\n",
    "Training a model that is able to discriminate between *real* and *fake*,\n",
    "is not entirely straightforward.\n",
    "The main problem is to obtain a reasonable dataset \n",
    "that represents both classes equally well.\n",
    "\n",
    "One solution is to use random noise for the *fake* inputs.\n",
    "However, this often makes things too easy\n",
    "and will not produce a particularly strong model.\n",
    "To counter this issue, we can use an adversarial attack \n",
    "to make the *fake* inputs appear more real\n",
    "after every epoch of discriminator training.\n",
    "This turns out to produce a reasonable discriminator\n",
    "as well as reasonably good *fake* inputs.\n",
    "\n",
    " > Implement the `update_fake_examples` method of the `RealOrFakeDataset`\n",
    " > to implement the approach described above.\n",
    " > Make sure to keep the adversarial examples in a valid range!\n",
    " \n",
    "**Hint:** You can use the `adversarial_attack` function from the previous exercise to compute adversarial examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:31.788464Z",
     "iopub.status.busy": "2023-05-30T18:57:31.788164Z",
     "iopub.status.idle": "2023-05-30T18:57:31.806657Z",
     "shell.execute_reply": "2023-05-30T18:57:31.805499Z",
     "shell.execute_reply.started": "2023-05-30T18:57:31.788439Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc04760cd8b799a28621276ee9af3b72",
     "grade": false,
     "grade_id": "cell-0dc5e70d199f26f7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RealOrFakeDataset(Dataset):\n",
    "    \"\"\" Dataset for enhancing a (small) dataset with fake inputs. \"\"\"\n",
    "    \n",
    "    def __init__(self, real_dataset, seed: int = None):\n",
    "        super().__init__()\n",
    "        self.ref_dataset = real_dataset\n",
    "        \n",
    "        # control randomness\n",
    "        rng = torch.Generator()\n",
    "        if seed is not None:\n",
    "            rng.manual_seed(seed)\n",
    "        \n",
    "        # get real, pre-processed data\n",
    "        real_data = torch.stack([x for x, _ in real_dataset])\n",
    "        mean, std = real_data.mean(), real_data.std()\n",
    "        min_x, max_x = real_data.min(), real_data.max()\n",
    "        self.min_x, self.max_x = min_x, max_x\n",
    "        # generate fake data (with similar statistics)\n",
    "        self.fake_data = torch.empty_like(real_data)\n",
    "        self.fake_data.normal_(mean, std, generator=rng).clamp_(min_x, max_x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        new_index = index - len(self.ref_dataset)\n",
    "        if new_index < 0:\n",
    "            x, _ = self.ref_dataset[index]\n",
    "            return x, torch.ones(1)\n",
    "        \n",
    "        return self.fake_data[new_index], torch.zeros(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ref_dataset) + len(self.fake_data)\n",
    "    \n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, 'MNIST', 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, 'MNIST', 'processed')\n",
    "    \n",
    "    def update_fake_examples(self, network: nn.Module, loss_func: nn.Module,\n",
    "                             epsilon: float = .1):\n",
    "        \"\"\"\n",
    "        Update the fake examples of this dataset.\n",
    "\n",
    "        The fake examples are updated by computing adversarial examples\n",
    "        for the network that is trained with the data from this dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        network : nn.Module\n",
    "            Network to use for computing adversarial examples.\n",
    "        loss_func : nn.Module\n",
    "            Loss function to use for computing adversarial examples.\n",
    "        epsilon : float, optional\n",
    "            Epsilon parameter for the adversarial attack.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        This method overwrites the fake samples.\n",
    "        It should not be necessary to create a new dataset\n",
    "        or set up a new data loader.\n",
    "        \"\"\"\n",
    "        device = next(network.parameters()).device\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        fake_copy = self.fake_data.clone().detach()#.requires_grad_(True).to(x.device)\n",
    "\n",
    "        batch_size = 32#64 # creating a batch to speed up the process\n",
    "        indexer = batch_size\n",
    "        round_ = 1\n",
    "        \n",
    "        while indexer == batch_size: \n",
    "            indexer = min(batch_size, fake_copy.shape[0])\n",
    "            fake_img_copy = fake_copy[:indexer]\n",
    "            fake_copy = fake_copy[indexer:]\n",
    "            \n",
    "            fake_img_copy.to(device)\n",
    "            y= torch.tensor([0]*fake_img_copy.shape[0], dtype=fake_img_copy.dtype).to(device)\n",
    "\n",
    "            new_fake_img_copy = adversarial_attack(fake_img_copy.to(device), y, network, loss_func, epsilon,steps=50)\n",
    "     \n",
    "            if indexer == batch_size:\n",
    "                self.fake_data[(round_-1)*batch_size:round_*batch_size] = new_fake_img_copy.clamp_(self.min_x.to(device), self.max_x.to(device))\n",
    "            else:\n",
    "                self.fake_data[(round_-1)*batch_size:] = new_fake_img_copy.clamp_(self.min_x.to(device), self.max_x.to(device))\n",
    "\n",
    "            round_+=1\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:31.808559Z",
     "iopub.status.busy": "2023-05-30T18:57:31.808206Z",
     "iopub.status.idle": "2023-05-30T18:57:32.440212Z",
     "shell.execute_reply": "2023-05-30T18:57:32.439231Z",
     "shell.execute_reply.started": "2023-05-30T18:57:31.808528Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c486661bcf832548b9db50b4cc1e550f",
     "grade": true,
     "grade_id": "cell-cfcadb4f82d394fa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "discriminator = Discriminator()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "data = RealOrFakeDataset(torch.utils.data.Subset(mnist_train, range(64)))\n",
    "\n",
    "old_samples = data.fake_data.clone()\n",
    "data.update_fake_examples(discriminator, bce)\n",
    "new_samples = data.fake_data\n",
    "assert torch.any(old_samples != new_samples), (\n",
    "    \"ex2: update_fake_examples does nothing (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e68346a1c9d72d3e56f00372591ad35",
     "grade": true,
     "grade_id": "cell-a1ce83fcff055786",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:32.441764Z",
     "iopub.status.busy": "2023-05-30T18:57:32.441405Z",
     "iopub.status.idle": "2023-05-30T18:57:32.452069Z",
     "shell.execute_reply": "2023-05-30T18:57:32.450956Z",
     "shell.execute_reply.started": "2023-05-30T18:57:32.441731Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5f7eedb71179170fe5487b4ddaa7620",
     "grade": true,
     "grade_id": "cell-7cc671490cc4b884",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert torch.all(discriminator(new_samples) > discriminator(old_samples)), (\n",
    "    \"ex2: update_fake_examples does not make samples more real (-1 point)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "869a57ec763b4e5b86748bd27eb4e35a",
     "grade": true,
     "grade_id": "cell-306bb1f47e6a79a3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Training the Discriminator (1 point)\n",
    "\n",
    "Finally, we can use this dataset for training the discriminator.\n",
    "By updating the *fake* inputs after every epoch of training,\n",
    "the quality of the *fake* inputs, and therefore also the discriminator,\n",
    "should improve steadily during training.\n",
    "\n",
    "Time to test if this actually works.\n",
    "The `train_discriminator` function (in the preamble)\n",
    "implements a training loop that updates the fake examples every epoch.\n",
    "The code below is able to train the discriminator to zero loss.\n",
    "However, the *fake* images do not look very realistic.\n",
    "\n",
    " > Play around with some of the hyperparameters (lr, epsilon, ...)\n",
    " > to get more realistic *fake* images,\n",
    " > so that the task of the discriminator becomes harder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T18:57:32.454751Z",
     "iopub.status.busy": "2023-05-30T18:57:32.453477Z",
     "iopub.status.idle": "2023-05-30T19:08:16.436147Z",
     "shell.execute_reply": "2023-05-30T19:08:16.432581Z",
     "shell.execute_reply.started": "2023-05-30T18:57:32.454714Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3943f5a5fb6e8ada879135ccf5660c6b",
     "grade": true,
     "grade_id": "cell-178513103ef77cd0",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 - avg loss: 0.686061\n",
      "D probs: 0.51, 0.49, 0.50, 0.54, 0.51, 0.53, 0.52, 0.52, 0.54, 0.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 - avg loss: 0.034885\n",
      "Epoch  2 - avg loss: 0.001891\n",
      "Epoch  3 - avg loss: 0.001948\n",
      "D probs: 0.85, 0.65, 0.07, 0.43, 0.20, 0.53, 0.44, 0.12, 0.60, 0.02\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m DiscriminatorTrainer(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mdiscriminator,\n\u001b[1;32m      7\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\u001b[38;5;66;03m#0.1\u001b[39;00m\n\u001b[1;32m     11\u001b[0m ) \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# batch_size = 32 in class RealOrFakeDataset(Dataset) speedens up the process.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvis_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[5], line 122\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, loader, num_epochs, vis_every)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# train for some epochs\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     errs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m 2d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - avg loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(errs)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(errs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m vis_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mDiscriminatorTrainer.update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DataLoader) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     22\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(data)\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_fake_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[19], line 81\u001b[0m, in \u001b[0;36mRealOrFakeDataset.update_fake_examples\u001b[0;34m(self, network, loss_func, epsilon)\u001b[0m\n\u001b[1;32m     78\u001b[0m fake_img_copy\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     79\u001b[0m y\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mfake_img_copy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mfake_img_copy\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 81\u001b[0m new_fake_img_copy \u001b[38;5;241m=\u001b[39m \u001b[43madversarial_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_img_copy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;241m==\u001b[39m batch_size:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfake_data[(round_\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size:round_\u001b[38;5;241m*\u001b[39mbatch_size] \u001b[38;5;241m=\u001b[39m new_fake_img_copy\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_x\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_x\u001b[38;5;241m.\u001b[39mto(device))\n",
      "Cell \u001b[0;32mIn[13], line 44\u001b[0m, in \u001b[0;36madversarial_attack\u001b[0;34m(x, y, network, loss_func, epsilon, eta, steps)\u001b[0m\n\u001b[1;32m     41\u001b[0m logits \u001b[38;5;241m=\u001b[39m network(_noisy_x)\n\u001b[1;32m     42\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# make logits comparable to y for the loss_func()       \u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# loss = - loss as we have gradient ascent instead of gradient descent\u001b[39;00m\n\u001b[1;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():          \n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:720\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3165\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m-> 3165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_data = RealOrFakeDataset(mnist_train)\n",
    "d_loader = DataLoader(d_data, batch_size=128, shuffle=True)\n",
    "\n",
    "discriminator = Discriminator().to(device)\n",
    "trainer = DiscriminatorTrainer(\n",
    "    model=discriminator,\n",
    "    criterion=nn.BCEWithLogitsLoss(),\n",
    "    optimiser=optim.Adam(discriminator.parameters(), lr=1e-4),#1e-2),\n",
    "    dataset=d_data,\n",
    "    epsilon=0.3#0.1\n",
    ") \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# batch_size = 32 in class RealOrFakeDataset(Dataset) speedens up the process.\n",
    "_ = trainer.train(d_loader, num_epochs=15, vis_every=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Modelling\n",
    "\n",
    "The previously discussed approach, using adversarial training,\n",
    "is able to create somewhat realistic inputs.\n",
    "Although it might be considered a way to generate new images,\n",
    "it is not very practical because it does not allow \n",
    "to generate samples after training.\n",
    "\n",
    "Although Generative Adversarial Nets (GANs)\n",
    "do not really have a connection with adversarial examples\n",
    "(except for the main author and the name),\n",
    "the goal is also to \"fool\" a discriminator network.\n",
    "Instead of using adversarial examples as *false* examples, however,\n",
    "GANs use a decoder-style network, referred to as *generator*\n",
    "that maps from a known distribution to the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T19:08:22.688455Z",
     "iopub.status.busy": "2023-05-30T19:08:22.688082Z",
     "iopub.status.idle": "2023-05-30T19:08:22.702512Z",
     "shell.execute_reply": "2023-05-30T19:08:22.701519Z",
     "shell.execute_reply.started": "2023-05-30T19:08:22.688425Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\" Network for creating fake MNIST images. \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim: int = 64):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim : int, optional\n",
    "            Dimensions of the latent space, from which to sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 32, 6),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(32, 8, 3, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(8, 1, 4, stride=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self.model(z.view(-1, self.latent_dim, 1, 1))\n",
    "        return x\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size: int):\n",
    "        \"\"\"\n",
    "        Sample in the latent space of the generator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Number of samples to sample.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        z : (batch_size, latent_dim) torch.Tensor\n",
    "            A random vector in the latent space.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Gradient computations are disabled.\n",
    "        \"\"\"\n",
    "        z = torch.randn(batch_size, self.latent_dim)\n",
    "        return z.to(self.model[0].weight.device)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, z = None, batch_size: int = 1, bounded: bool = True):\n",
    "        \"\"\"\n",
    "        Generate one or more random images.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : (N, latent_dim) torch.Tensor\n",
    "            Latent vector(s) to use for generation.\n",
    "        batch_size : int, optional\n",
    "            Number of images to generate.\n",
    "            This parameter is ignored if `z` is specified.\n",
    "        bounded : bool, optional\n",
    "            Flag to assure that pixel values are in a valid range.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : (batch_size, C, H, W) torch.Tensor\n",
    "            Generated image(s).\n",
    "        \"\"\"\n",
    "        if z is None:\n",
    "            z = self.sample(batch_size)\n",
    "        \n",
    "        raw = self.forward(z)\n",
    "        \n",
    "        if bounded:\n",
    "            raw.clamp_(-0.4242, 2.8215)  # MNIST range\n",
    "            \n",
    "        return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 4: Min-Max Game (5 points)\n",
    "\n",
    "\n",
    "The goal of the generator is to create images that maximise the loss\n",
    "that the discriminator attempts to minimise.\n",
    "The result is a min-max game between generator and discriminator.\n",
    "Mathematically, this leads to the following optimisation target:\n",
    "$$\\begin{aligned}\n",
    "\\max_d \\min_g \\mathbb{E}[\\log d(X)] + \\mathbb{E}[\\log(1 - d(g(Z)))].\n",
    "\\end{aligned}$$\n",
    "Note that this function is simply the negated binary cross-entropy loss.\n",
    "\n",
    " > Finish the implementation of the `update_gan` function,\n",
    " > including the `generator_error` and `discriminator_error` functions.\n",
    " > Make sure that the generator-error is used to update only the generator,\n",
    " > i.e. does not affect the discriminator, and vice versa.\n",
    " > To achieve this, you will need to control the gradients\n",
    " > with the techniques discussed in assignment 1.\n",
    " > Also, you do not want to directly maximise the error term for the generator,\n",
    " > since it suffers from vanishing gradients.\n",
    " > Think about an alternative, but equivalent optimisation problem.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:08:25.108290Z",
     "iopub.status.busy": "2023-05-30T19:08:25.107495Z",
     "iopub.status.idle": "2023-05-30T19:08:25.115669Z",
     "shell.execute_reply": "2023-05-30T19:08:25.114637Z",
     "shell.execute_reply.started": "2023-05-30T19:08:25.108254Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79b63e62435a83c1104844838c580f85",
     "grade": false,
     "grade_id": "cell-1cff57f62d3dec3b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generator_error(gan: nn.Module, real_x: torch.Tensor, loss_func: nn.Module):\n",
    "    \"\"\"\n",
    "    Construct the gradient graph for updating the generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gan : nn.Module\n",
    "        Module with `generator` and `discriminator` sub-modules.\n",
    "    real_x: torch.Tensor\n",
    "        Mini-batch from target distribution.\n",
    "    loss_func: nn.Module\n",
    "        Loss function taking logits and target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    err : torch.Tensor\n",
    "        Scalar tensor with graph for updating generator.\n",
    "    \"\"\" \n",
    "    # only d(g(z)) objective is needed:\n",
    "    \n",
    "    g = gan['generator']\n",
    "    g.requires_grad_(True)\n",
    "    \n",
    "    d = gan['discriminator']\n",
    "    d.requires_grad_(False)\n",
    "    \n",
    "    # generate z:\n",
    "    gg = gan['generator']\n",
    "    sampled_z = g.sample(batch_size=real_x.shape[0])\n",
    "   # sampled_z.requires_grad = True\n",
    "    \n",
    "    fake_img = g(sampled_z)\n",
    "    # don't use g.generate(z=sampled_z) as it breaks the gradient flow within gan!\n",
    "    fake_img.requires_grad_(True)\n",
    "\n",
    "    logit = d(fake_img)\n",
    "\n",
    "    y = torch.ones_like(logit, dtype=logit.dtype)\n",
    "\n",
    "    loss = loss_func(logit,y)\n",
    "    \n",
    "    return loss\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:08:26.353796Z",
     "iopub.status.busy": "2023-05-30T19:08:26.353138Z",
     "iopub.status.idle": "2023-05-30T19:08:26.382370Z",
     "shell.execute_reply": "2023-05-30T19:08:26.381487Z",
     "shell.execute_reply.started": "2023-05-30T19:08:26.353760Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "390dc45bd690c234914ebbb2d1402507",
     "grade": true,
     "grade_id": "cell-d7f3d119c11b44db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "gan = nn.ModuleDict({\n",
    "    'generator': Generator(),\n",
    "    'discriminator': Discriminator()\n",
    "})\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "try:\n",
    "    err = generator_error(gan, torch.randn(5, 1, 28, 28), bce)\n",
    "    grads = torch.autograd.grad(err, gan.generator.parameters())\n",
    "except RuntimeError:\n",
    "    raise AssertionError(\n",
    "        \"ex4: generator_error does not allow to compute gradients (-1 point)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:08:27.767825Z",
     "iopub.status.busy": "2023-05-30T19:08:27.766648Z",
     "iopub.status.idle": "2023-05-30T19:08:27.772737Z",
     "shell.execute_reply": "2023-05-30T19:08:27.771503Z",
     "shell.execute_reply.started": "2023-05-30T19:08:27.767774Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48141330461ff9ad09e260ffa0fe9bbf",
     "grade": true,
     "grade_id": "cell-07d5f9f287635c6a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:08:28.954328Z",
     "iopub.status.busy": "2023-05-30T19:08:28.951860Z",
     "iopub.status.idle": "2023-05-30T19:08:28.962494Z",
     "shell.execute_reply": "2023-05-30T19:08:28.961601Z",
     "shell.execute_reply.started": "2023-05-30T19:08:28.954282Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d7a2d82d3a7b41c0ad291d1c800394c",
     "grade": false,
     "grade_id": "cell-37342f54487640f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discriminator_error(gan: nn.Module, real_x: torch.Tensor, loss_func: nn.Module):\n",
    "    \"\"\"\n",
    "    Construct the gradient graph for updating the discriminator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gan : nn.Module\n",
    "        Module with `generator` and `discriminator` sub-modules.\n",
    "    real_x: torch.Tensor\n",
    "        Mini-batch from target distribution.\n",
    "    loss_func: nn.Module\n",
    "        Loss function taking logits and target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    err : torch.Tensor\n",
    "        Scalar tensor with graph for updating discriminator.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    g = gan['generator']\n",
    "    g.requires_grad_(False) \n",
    "\n",
    "    d = gan['discriminator']\n",
    "    d.requires_grad_(True) \n",
    "\n",
    "    # d(x) objective:\n",
    "    real_x.requires_grad=True\n",
    "    logit = d(real_x)\n",
    "    y = torch.ones_like(logit, dtype=logit.dtype)\n",
    "    loss = loss_func(logit, y)\n",
    "\n",
    "    # d(g(z)) objective:\n",
    "    sampled = g.sample(batch_size=real_x.shape[0])\n",
    "    fake_img = g(sampled)\n",
    "    fake_img.requires_grad_()\n",
    "\n",
    "    logit2 = d(fake_img)\n",
    "    y2 = torch.zeros_like(logit2, dtype=logit2.dtype)\n",
    "    loss2 = loss_func(logit2, y2)\n",
    "\n",
    "    return (loss+loss2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:08:30.295458Z",
     "iopub.status.busy": "2023-05-30T19:08:30.295086Z",
     "iopub.status.idle": "2023-05-30T19:08:30.313505Z",
     "shell.execute_reply": "2023-05-30T19:08:30.312641Z",
     "shell.execute_reply.started": "2023-05-30T19:08:30.295428Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19a50aab07131c142c6ab1635c8d71f9",
     "grade": true,
     "grade_id": "cell-7829942b0b34da1e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "gan = nn.ModuleDict({\n",
    "    'generator': Generator(),\n",
    "    'discriminator': Discriminator()\n",
    "})\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "try:\n",
    "    err = discriminator_error(gan, torch.randn(5, 1, 28, 28), bce)\n",
    "    grads = torch.autograd.grad(err, gan.discriminator.parameters())\n",
    "except RuntimeError:\n",
    "    raise AssertionError(\n",
    "        \"ex4: discriminator_error does not allow to compute gradients (-1 point)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T14:21:33.410463Z",
     "iopub.status.busy": "2023-05-30T14:21:33.410046Z",
     "iopub.status.idle": "2023-05-30T14:21:33.416034Z",
     "shell.execute_reply": "2023-05-30T14:21:33.415142Z",
     "shell.execute_reply.started": "2023-05-30T14:21:33.410432Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67508223a643a3dd171f6b93d26f2d9c",
     "grade": true,
     "grade_id": "cell-ed73a7012b9323b0",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:09:05.196235Z",
     "iopub.status.busy": "2023-05-30T19:09:05.195842Z",
     "iopub.status.idle": "2023-05-30T19:09:05.209582Z",
     "shell.execute_reply": "2023-05-30T19:09:05.208607Z",
     "shell.execute_reply.started": "2023-05-30T19:09:05.196202Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95ed553d8ecb2ab39b4c7a509cc16002",
     "grade": false,
     "grade_id": "cell-d3639e99db870a93",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_gan(gan: nn.Module, loader: DataLoader, loss_func: nn.Module,\n",
    "               opt: optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Train GAN for one epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gan : nn.Module\n",
    "        Module with `generator` and `discriminator` sub-modules.\n",
    "    loader : DataLoader\n",
    "        Standard, supervised data loader with samples from target distribution.\n",
    "    loss_func : nn.Module\n",
    "        Loss function taking logits and target values.\n",
    "    opt : optim.Optimizer\n",
    "        Optimiser for updating GAN parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    g_errs : list\n",
    "        List of computed errors for generator update in each batch.\n",
    "    d_errs : list\n",
    "        List of computed errors for discriminator update in each batch.\n",
    "    \"\"\" \n",
    "    gan.train()\n",
    "    device = next(gan.parameters()).device\n",
    "    \n",
    "    d_errs, g_errs = [], []\n",
    "    for x, _ in loader:\n",
    "        x = x.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "\n",
    "        g_err = generator_error(gan, x, loss_func)\n",
    "        g_err.backward() # has to follow directly after g_err. When d_err is defined \n",
    "        # before this line then g_err.backward() doesn't work anymore. Observed was this by the fact that\n",
    "        # only the parameters of d_err.backward()/discriminator were updated\n",
    "\n",
    "        \n",
    "        d_err = discriminator_error(gan, x, loss_func)\n",
    "        d_err.backward()\n",
    "        \n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "        g_errs.append(g_err)\n",
    "        d_errs.append(d_err)\n",
    "        \n",
    "\n",
    "    return g_errs, d_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:09:06.412585Z",
     "iopub.status.busy": "2023-05-30T19:09:06.412208Z",
     "iopub.status.idle": "2023-05-30T19:09:06.891433Z",
     "shell.execute_reply": "2023-05-30T19:09:06.890038Z",
     "shell.execute_reply.started": "2023-05-30T19:09:06.412555Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c87baf883456c6c964b0d5dad00149a",
     "grade": true,
     "grade_id": "cell-99b7d4927c903c5b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "gan = nn.ModuleDict({\n",
    "    'generator': Generator(),\n",
    "    'discriminator': Discriminator()\n",
    "}).to(device)\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "opt = optim.Adam(gan.parameters(), lr=1e-3)\n",
    "\n",
    "old_pars = {k: v.clone() for k, v in gan.state_dict().items()}\n",
    "g_errs, d_errs = update_gan(gan, [next(iter(train_loader))], bce, opt)\n",
    "assert len(g_errs) == len(test_loader), (\n",
    "    \"ex4: wrong number of generator errors in update_gan(-0.5 points)\"\n",
    ")\n",
    "assert len(d_errs) == len(test_loader), (\n",
    "    \"ex4: wrong number of discriminator errors in update_gan (-0.5 points)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2023-05-30T19:09:08.155769Z",
     "iopub.status.busy": "2023-05-30T19:09:08.154672Z",
     "iopub.status.idle": "2023-05-30T19:09:08.164245Z",
     "shell.execute_reply": "2023-05-30T19:09:08.163178Z",
     "shell.execute_reply.started": "2023-05-30T19:09:08.155721Z"
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e10577dbc5341dc52ffa356c93bc15c",
     "grade": true,
     "grade_id": "cell-7ed80050c64cdb4d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!\n",
    "assert all(\n",
    "    torch.any(old_pars[k] != par) for k, par in gan.state_dict().items()\n",
    "), \"ex4: update_gan does not update all parameters (-1 points)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ccf8ae97e2981e21139370274f8ed0f",
     "grade": true,
     "grade_id": "cell-495ee05cc9204fba",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Cell: do not edit or delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T19:09:12.980174Z",
     "iopub.status.busy": "2023-05-30T19:09:12.979558Z",
     "iopub.status.idle": "2023-05-30T19:10:41.751465Z",
     "shell.execute_reply": "2023-05-30T19:10:41.749524Z",
     "shell.execute_reply.started": "2023-05-30T19:09:12.980140Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 - avg G loss: 0.63932, avg D loss: 0.71126\n",
      "D probs: 0.53, 0.53, 0.53, 0.53, 0.53, 0.53, 0.53, 0.53, 0.53, 0.53\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 - avg G loss: 1.84802, avg D loss: 0.39643\n",
      "Epoch  2 - avg G loss: 1.08894, avg D loss: 0.53932\n",
      "Epoch  3 - avg G loss: 0.85911, avg D loss: 0.63885\n",
      "Epoch  4 - avg G loss: 0.76370, avg D loss: 0.68838\n",
      "Epoch  5 - avg G loss: 0.78722, avg D loss: 0.65992\n",
      "D probs: 0.55, 0.51, 0.58, 0.61, 0.55, 0.63, 0.48, 0.44, 0.56, 0.53\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=280x28>"
      ]
     },
     "metadata": {
      "width": "100%"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m bce \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[1;32m      7\u001b[0m opt \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam([\n\u001b[1;32m      8\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: gan\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-3\u001b[39m},\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: gan\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2e-4\u001b[39m}\n\u001b[1;32m     10\u001b[0m ])\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 64\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m(gan, loader, objective, optimiser, num_epochs, vis_every)\u001b[0m\n\u001b[1;32m     61\u001b[0m display_fakes(gan\u001b[38;5;241m.\u001b[39mdiscriminator, fake_data)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     g_errs, d_errs \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     loss_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg G loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(g_errs)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(g_errs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg D loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(d_errs)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(d_errs)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     ])\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m 2d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, loss_report, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m, in \u001b[0;36mupdate_gan\u001b[0;34m(gan, loader, loss_func, opt)\u001b[0m\n\u001b[1;32m     25\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(gan\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     27\u001b[0m d_errs, g_errs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, _ \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "gan = nn.ModuleDict({\n",
    "    'generator': Generator(),\n",
    "    'discriminator': Discriminator()\n",
    "}).to(device)\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "opt = optim.Adam([\n",
    "    {'params': gan.generator.parameters(), 'lr': 1e-3},\n",
    "    {'params': gan.discriminator.parameters(), 'lr': 2e-4}\n",
    "])\n",
    "train_gan(gan, train_loader, bce, opt, num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
